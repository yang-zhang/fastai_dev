{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.all import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "pd.set_option('mode.chained_assignment','raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp tabular.core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular core\n",
    "\n",
    "> Basic function to preprocess tabular data before assembling it in a `DataBunch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tabular(CollBase):\n",
    "    \"A `DataFrame` wrapper that knows which cols are cont/cat/y, and returns rows in `__getitem__`\"\n",
    "    def __init__(self, df, cat_names=None, cont_names=None, y_names=None, is_y_cat=True, split=None):\n",
    "        super().__init__(df)\n",
    "        store_attr(self, 'y_names,is_y_cat,split')\n",
    "        self.cat_names,self.cont_names = L(cat_names),L(cont_names)\n",
    "        self.cat_y  = None if not is_y_cat else y_names\n",
    "        self.cont_y = None if     is_y_cat else y_names\n",
    "\n",
    "    def _new(self, df):\n",
    "        return Tabular(df, self.cat_names, self.cont_names, self.y_names, is_y_cat=self.is_y_cat, split=self.split)\n",
    "\n",
    "    def set_col(self,k,v): super().__setitem__(k, v)\n",
    "    def show(self, max_n=10, **kwargs): display_df(self.all_cols[:max_n])\n",
    "\n",
    "    def __getitem__(self, idxs):\n",
    "        \"Get/set rows by iloc and cols by name\"\n",
    "        rows,cols = idxs if isinstance(idxs,tuple) else (idxs,None)\n",
    "        f = self.items.columns.get_loc\n",
    "        c = (slice(None) if cols is None\n",
    "             else L(cols).mapped(f) if is_listy(cols)\n",
    "             else f(cols))\n",
    "        return self._new(self.items.iloc[rows, c])\n",
    "\n",
    "    def __getattr__(self,k):\n",
    "        if k.startswith('_') or k=='items': raise AttributeError\n",
    "        return getattr(self.items,k)\n",
    "\n",
    "    @property\n",
    "    def iloc(self): return self\n",
    "    @property\n",
    "    def targ(self): return self.items[self.y_names]\n",
    "    @property\n",
    "    def all_cont_names(self): return self.cont_names + self.cont_y\n",
    "    @property\n",
    "    def all_cat_names (self): return self.cat_names  + self.cat_y\n",
    "    @property\n",
    "    def all_col_names (self): return self.all_cont_names + self.all_cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TabularPandas(Tabular):\n",
    "    def transform(self, cols, f): self.set_col(cols, self[:,cols].transform(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _add_prop(cls, nm):\n",
    "    prop = property(lambda o: o.items[list(getattr(o,nm+'_names'))])\n",
    "    setattr(cls, nm+'s', prop)\n",
    "    def _f(o,v): o.set_col(getattr(o,nm+'_names'), v)\n",
    "    setattr(cls, nm+'s', prop.setter(_f))\n",
    "\n",
    "_add_prop(Tabular, 'cat')\n",
    "_add_prop(Tabular, 'all_cat')\n",
    "_add_prop(Tabular, 'cont')\n",
    "_add_prop(Tabular, 'all_cont')\n",
    "_add_prop(Tabular, 'all_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[0,1,2,0,2], 'b':[0,0,0,0,1]})\n",
    "to = TabularPandas(df, 'a')\n",
    "t = pickle.loads(pickle.dumps(to))\n",
    "test_eq(t.items,to.items)\n",
    "to.show() # only shows 'a' since that's the only col in `TabularPandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TabularProc(InplaceTransform):\n",
    "    \"Base class to write a non-lazy tabular processor for dataframes\"\n",
    "    def setup(self, items=None):\n",
    "        super().setup(items)\n",
    "        # Procs are called as soon as data is available\n",
    "        return self(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Categorify(TabularProc, CollBase):\n",
    "    \"Transform the categorical variables to that type.\"\n",
    "    order = 1\n",
    "    def __init__(self): self.items=[]\n",
    "    def setups(self, to):\n",
    "        to.classes = self.items = {n:CategoryMap(to[:to.split,n], add_na=True)\n",
    "                                   for n in to.all_cat_names}\n",
    "\n",
    "    def _apply_cats (self, c): return c.cat.codes+1 if is_categorical_dtype(c) else c.map(self[c.name].o2i)\n",
    "    def _decode_cats(self, c): return c.map(dict(enumerate(self[c.name].items)))\n",
    "    def encodes(self, to): to.transform(to.all_cat_names, self._apply_cats)\n",
    "    def decodes(self, to): to.transform(to.all_cat_names, self._decode_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"Categorify\" class=\"doc_header\"><code>class</code> <code>Categorify</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>Categorify</code>() :: [`TabularProc`](/tabular.core.html#TabularProc)\n",
       "\n",
       "Transform the categorical variables to that type."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Categorify, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorify()\n",
    "df = pd.DataFrame({'a':[0,1,2,0,2]})\n",
    "to = TabularPandas(df, 'a')\n",
    "cat.setup(to)\n",
    "test_eq(cat['a'], ['#na#',0,1,2])\n",
    "test_eq(df['a'], [1,2,3,1,3])\n",
    "df1 = pd.DataFrame({'a':[1,0,3,-1,2]})\n",
    "\n",
    "to1 = TabularPandas(df1, 'a')\n",
    "cat(to1)\n",
    "#Values that weren't in the training df are sent to 0 (na)\n",
    "test_eq(df1['a'], [2,1,0,0,3])\n",
    "to2 = cat.decode(to1)\n",
    "test_eq(to2.a, [1,0,'#na#','#na#',2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with splits\n",
    "cat = Categorify()\n",
    "df = pd.DataFrame({'a':[0,1,2,3,2]})\n",
    "to = TabularPandas(df, 'a', split=3)\n",
    "cat.setup(to)\n",
    "test_eq(cat['a'], ['#na#',0,1,2])\n",
    "test_eq(df['a'], [1,2,3,0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True)})\n",
    "to = TabularPandas(df, 'a')\n",
    "cat = Categorify()\n",
    "cat.setup(to)\n",
    "test_eq(cat['a'], ['#na#','H','M','L'])\n",
    "test_eq(df.a, [2,1,3,2])\n",
    "to2 = cat.decode(to)\n",
    "test_eq(to2.a, ['M','H','L','M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Normalize(TabularProc):\n",
    "    \"Normalize the continuous variables.\"\n",
    "    order = 2\n",
    "    def setups(self, to):\n",
    "        df = to[:to.split, to.cont_names]\n",
    "        self.means,self.stds = df.mean(),df.std(ddof=0)+1e-7\n",
    "\n",
    "    def encodes(self, to): to.conts = (to.conts-self.means) / self.stds\n",
    "    def decodes(self, to): to.conts = (to.conts*self.stds ) + self.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"Normalize\" class=\"doc_header\"><code>class</code> <code>Normalize</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>Normalize</code>(**`enc`**=*`None`*, **`dec`**=*`None`*, **`filt`**=*`None`*, **`as_item`**=*`False`*) :: [`TabularProc`](/tabular.core.html#TabularProc)\n",
       "\n",
       "Normalize the continuous variables."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Normalize, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalize()\n",
    "df = pd.DataFrame({'a':[0,1,2,3,4]})\n",
    "to = TabularPandas(df, cont_names='a')\n",
    "norm.setup(to)\n",
    "x = np.array([0,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_eq(norm.means['a'], m)\n",
    "test_close(norm.stds['a'], s)\n",
    "test_close(df['a'].values, (x-m)/s)\n",
    "df1 = pd.DataFrame({'a':[5,6,7]})\n",
    "to1 = TabularPandas(df1, cont_names='a')\n",
    "norm(to1)\n",
    "test_close(df1['a'].values, (np.array([5,6,7])-m)/s)\n",
    "to2 = norm.decode(to1)\n",
    "test_close(to2.a.values, [5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalize()\n",
    "df = pd.DataFrame({'a':[0,1,2,3,4]})\n",
    "to = TabularPandas(df, cont_names='a', split=3)\n",
    "norm.setup(to)\n",
    "x = np.array([0,1,2])\n",
    "m,s = x.mean(),x.std()\n",
    "test_eq(norm.means['a'], m)\n",
    "test_close(norm.stds['a'], s)\n",
    "test_close(df['a'].values, (np.array([0,1,2,3,4])-m)/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FillStrategy:\n",
    "    \"Namespace containing the various filling strategies.\"\n",
    "    def median  (c,fill): return c.median()\n",
    "    def constant(c,fill): return fill\n",
    "    def mode    (c,fill): return c.dropna().value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FillMissing(TabularProc):\n",
    "    \"Fill the missing values in continuous columns.\"\n",
    "    def __init__(self, fill_strategy=FillStrategy.median, add_col=True, fill_vals=None):\n",
    "        if fill_vals is None: fill_vals = defaultdict(int)\n",
    "        store_attr(self, 'fill_strategy,add_col,fill_vals')\n",
    "\n",
    "    def setups(self, to):\n",
    "        df = to[:to.split, to.cont_names].items\n",
    "        self.na_dict = {n:self.fill_strategy(df[n], self.fill_vals[n])\n",
    "                        for n in pd.isnull(to.conts).any().keys()}\n",
    "\n",
    "    def encodes(self, to):\n",
    "        missing = pd.isnull(to.conts)\n",
    "        for n in missing.any().keys():\n",
    "            assert n in self.na_dict, f\"nan values in `{n}` but not in setup training set\"\n",
    "            to[:,n].fillna(self.na_dict[n], inplace=True)\n",
    "            if self.add_col:\n",
    "                to.loc[:,n+'_na'] = missing[n]\n",
    "                if n+'_na' not in to.cat_names: to.cat_names.append(n+'_na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"FillMissing\" class=\"doc_header\"><code>class</code> <code>FillMissing</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>FillMissing</code>(**`fill_strategy`**=*`'median'`*, **`add_col`**=*`True`*, **`fill_vals`**=*`None`*) :: [`TabularProc`](/tabular.core.html#TabularProc)\n",
       "\n",
       "Fill the missing values in continuous columns."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FillMissing, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill1,fill2,fill3 = (FillMissing(fill_strategy=s) \n",
    "                     for s in [FillStrategy.median, FillStrategy.constant, FillStrategy.mode])\n",
    "df = pd.DataFrame({'a':[0,1,np.nan,1,2,3,4]})\n",
    "df1 = df.copy(); df2 = df.copy()\n",
    "to,to1,to2 = TabularPandas(df, cont_names='a'),TabularPandas(df1, cont_names='a'),TabularPandas(df2, cont_names='a')\n",
    "fill1.setup(to); fill2.setup(to1); fill3.setup(to2)\n",
    "test_eq(fill1.na_dict, {'a': 1.5})\n",
    "test_eq(fill2.na_dict, {'a': 0})\n",
    "test_eq(fill3.na_dict, {'a': 1.0})\n",
    "\n",
    "for t in [to, to1, to2]: test_eq(t.cat_names, ['a_na'])\n",
    "\n",
    "for to_,v in zip([to, to1, to2], [1.5, 0., 1.]):\n",
    "    test_eq(to_.a.values, np.array([0, 1, v, 1, 2, 3, 4]))\n",
    "    test_eq(to_.a_na.values, np.array([0, 0, 1, 0, 0, 0, 0]))\n",
    "    \n",
    "dfa = pd.DataFrame({'a':[np.nan,0,np.nan]})\n",
    "dfa1 = dfa.copy(); dfa2 = dfa.copy()\n",
    "to,to1,to2 = TabularPandas(dfa, cont_names='a'),TabularPandas(dfa1, cont_names='a'),TabularPandas(dfa2, cont_names='a')\n",
    "fill1(to); fill2(to1); fill3(to2)\n",
    "for to_,v in zip([to, to1, to2], [1.5, 0., 1.]):\n",
    "    test_eq(to_.a.values, np.array([v, 0, v]))\n",
    "    test_eq(to_.a_na.values, np.array([1, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularPandas Pipelines -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [Normalize(), Categorify(), FillMissing(), noop]\n",
    "proc = Pipeline(procs)\n",
    "\n",
    "#Test reordering and partialize\n",
    "test_eq(L(proc.fs).mapped(type), [FillMissing, Transform, Categorify, Normalize])\n",
    "\n",
    "df = pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4]})\n",
    "to = TabularPandas(df, 'a', 'b')\n",
    "\n",
    "#Test setup and apply on df_trn\n",
    "proc.setup(to)\n",
    "test_eq(to.cat_names, ['a', 'b_na'])\n",
    "test_eq(to.a, [1,2,3,2,2,3,1])\n",
    "test_eq(to.b_na, [1,1,2,1,1,1,1])\n",
    "x = np.array([0,1,1.5,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_close(to.b.values, (x-m)/s)\n",
    "test_eq(proc.classes, {'a': ['#na#',0,1,2], 'b_na': ['#na#',False,True]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test apply on y_names\n",
    "procs = [Normalize(), Categorify(), FillMissing(), noop]\n",
    "proc = Pipeline(procs)\n",
    "\n",
    "df = pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4], 'c': ['b','a','b','a','a','b','a']})\n",
    "to = TabularPandas(df, 'a', 'b', y_names='c')\n",
    "proc.setup(to)\n",
    "test_eq(to.cat_names, ['a', 'b_na'])\n",
    "test_eq(to.a, [1,2,3,2,2,3,1])\n",
    "test_eq(to.b_na, [1,1,2,1,1,1,1])\n",
    "test_eq(to.c, [2,1,2,1,1,2,1])\n",
    "x = np.array([0,1,1.5,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_close(to.b.values, (x-m)/s)\n",
    "test_eq(proc.classes, {'a': ['#na#',0,1,2], 'b_na': ['#na#',False,True], 'c': ['#na#','a','b']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TabularPandas)\n",
    "def process_df(df, procs, inplace=True, splits=None, **kwargs):\n",
    "    \"Process `df` with `procs` and returns the processed dataframe and the `TabularProcessor` associated\"\n",
    "    df = df if inplace else df.copy()\n",
    "    if splits is not None: df = df.iloc[sum(splits, [])].reset_index(drop=True)\n",
    "    split = None if splits is None else len(splits[0])\n",
    "    to = TabularPandas(df, split=split, **kwargs)\n",
    "    proc = Pipeline(procs)\n",
    "    proc.setup(to)\n",
    "    return to,proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [Normalize, Categorify, FillMissing, noop]\n",
    "df = pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4], 'c': ['b','a','b','a','a','b','a']})\n",
    "to,proc = process_df(df, procs, cat_names='a', cont_names='b', y_names='c', inplace=False)\n",
    "test_eq(to.cat_names, ['a', 'b_na'])\n",
    "test_eq(to.a, [1,2,3,2,2,3,1])\n",
    "test_eq(df.a.dtype,int)\n",
    "test_eq(to.b_na, [1,1,2,1,1,1,1])\n",
    "test_eq(to.c, [2,1,2,1,1,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [Normalize, Categorify, FillMissing, noop]\n",
    "df = pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,np.nan,1,1,2,3,4], 'c': ['b','a','b','a','a','b','a']})\n",
    "to,proc = process_df(df, procs, cat_names='a', cont_names='b', y_names='c', inplace=True, splits=[[0,1,4,6], [2,3,5]])\n",
    "test_eq(to.cat_names, ['a', 'b_na'])\n",
    "test_eq(to.a, [1,2,2,1,0,2,0])\n",
    "test_eq(df.a.dtype,int)\n",
    "test_eq(to.b_na, [1,2,1,1,1,1,1])\n",
    "test_eq(to.c, [2,1,1,1,2,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the same `splits` as you will use for splitting the data, so that the setup is only done on the training set. `cat_names` are the names of the categorical variables, `cont_names` the continous ones, `y_names` are the names of the dependent variables that are categories. If `inplace=True`, processing is applied inplace, otherwis it creates a copy of `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ReadTabBatch(ItemTransform):\n",
    "    def __init__(self, proc): self.proc = proc\n",
    "    def encodes(self, to): return (tensor(to.cats).long(),tensor(to.conts).float()), tensor(to.targ).long()\n",
    "\n",
    "    def decodes(self, o):\n",
    "        (cats,conts),targs = to_np(o)\n",
    "        vals = np.concatenate([cats,conts,targs[:,None]], axis=1)\n",
    "        df = pd.DataFrame(vals, columns=self.proc.cat_names+self.proc.cont_names+self.proc.y_names)\n",
    "        to = TabularPandas(df, self.proc.cat_names, self.proc.cont_names, self.proc.y_names, is_y_cat=self.proc.cat_y is not None)\n",
    "        to = self.proc.decode(to)\n",
    "        return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates()\n",
    "class TabDataLoader(TfmdDL):\n",
    "    do_item = noops\n",
    "    def __init__(self, dataset, proc, bs=16, shuffle=False, after_batch=None, num_workers=0, **kwargs):\n",
    "        after_batch = L(after_batch)+ReadTabBatch(proc)\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)\n",
    "\n",
    "    def create_batch(self, b): return self.dataset.items[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>101320</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>236746</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>96185</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>112847</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>82297</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt     education  education-num  \\\n",
       "0   49            Private  101320    Assoc-acdm           12.0   \n",
       "1   44            Private  236746       Masters           14.0   \n",
       "2   38            Private   96185       HS-grad            NaN   \n",
       "3   38       Self-emp-inc  112847   Prof-school           15.0   \n",
       "4   42   Self-emp-not-inc   82297       7th-8th            NaN   \n",
       "\n",
       "        marital-status        occupation    relationship                 race  \\\n",
       "0   Married-civ-spouse               NaN            Wife                White   \n",
       "1             Divorced   Exec-managerial   Not-in-family                White   \n",
       "2             Divorced               NaN       Unmarried                Black   \n",
       "3   Married-civ-spouse    Prof-specialty         Husband   Asian-Pac-Islander   \n",
       "4   Married-civ-spouse     Other-service            Wife                Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country salary  \n",
       "0   Female             0          1902              40   United-States  >=50k  \n",
       "1     Male         10520             0              45   United-States  >=50k  \n",
       "2   Female             0             0              32   United-States   <50k  \n",
       "3     Male             0             0              40   United-States  >=50k  \n",
       "4   Female             0             0              50   United-States   <50k  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')\n",
    "df_trn,df_tst = df.iloc[:10000].copy(),df.iloc[10000:].copy()\n",
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify(), FillMissing(), Normalize()]\n",
    "\n",
    "splits = RandomSplitter()(range_of(df_trn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 429 ms, sys: 0 ns, total: 429 ms\n",
      "Wall time: 429 ms\n"
     ]
    }
   ],
   "source": [
    "%time to,proc = process_df(df_trn, procs, splits=splits, cat_names=cat_names, cont_names=cont_names, y_names=\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>age_na</th>\n",
       "      <th>fnlwgt_na</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.000001</td>\n",
       "      <td>34917.999817</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>124918.998585</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>72743.004488</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>201734.000148</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>254303.002231</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>358885.999389</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>215479.000208</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>227594.000948</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>116103.001857</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>178207.000562</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filts = [list(range(len(splits[0]))), list(range(len(splits[0]), 10000))]\n",
    "dsrc = DataSource(to, filts=filts, tfms=[None])\n",
    "dl = TabDataLoader(dsrc.valid, proc, bs=64, num_workers=0)\n",
    "dl.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>age_na</th>\n",
       "      <th>fnlwgt_na</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.461170</td>\n",
       "      <td>1.335778</td>\n",
       "      <td>1.179782</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>-0.931596</td>\n",
       "      <td>1.249125</td>\n",
       "      <td>-0.422230</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>1.047598</td>\n",
       "      <td>0.151123</td>\n",
       "      <td>-1.223237</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>0.534474</td>\n",
       "      <td>-0.280144</td>\n",
       "      <td>-0.422230</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>0.754384</td>\n",
       "      <td>1.437878</td>\n",
       "      <td>0.378776</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education-num  workclass  education  \\\n",
       "10000  0.461170  1.335778       1.179782          5         10   \n",
       "10001 -0.931596  1.249125      -0.422230          5         12   \n",
       "10002  1.047598  0.151123      -1.223237          5          2   \n",
       "10003  0.534474 -0.280144      -0.422230          5         12   \n",
       "10004  0.754384  1.437878       0.378776          6          9   \n",
       "\n",
       "       marital-status  occupation  relationship  race  age_na  fnlwgt_na  \\\n",
       "10000               3           2             1     2       1          1   \n",
       "10001               3          15             1     4       1          1   \n",
       "10002               1           9             2     5       1          1   \n",
       "10003               7           2             5     5       1          1   \n",
       "10004               3           5             1     5       1          1   \n",
       "\n",
       "       education-num_na  salary  \n",
       "10000                 1       1  \n",
       "10001                 1       1  \n",
       "10002                 1       1  \n",
       "10003                 1       1  \n",
       "10004                 1       2  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_tst = TabularPandas(df_tst, cat_names, cont_names, y_names=\"salary\")\n",
    "proc(to_tst)\n",
    "to_tst.all_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not being used now - for multi-modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorTabular(TupleBase):\n",
    "    def get_ctxs(self, max_n=10, **kwargs):\n",
    "        n_samples = min(self[0].shape[0], max_n)\n",
    "        df = pd.DataFrame(index = range(n_samples))\n",
    "        return [df.iloc[i] for i in range(n_samples)]\n",
    "\n",
    "    def display(self, ctxs): display_df(pd.DataFrame(ctxs))\n",
    "\n",
    "class TabularLine(pd.Series):\n",
    "    \"A line of a dataframe that knows how to show itself\"\n",
    "    def show(self, ctx=None, **kwargs): return self if ctx is None else ctx.append(self)\n",
    "\n",
    "class ReadTabLine(ItemTransform):\n",
    "    def __init__(self, proc): self.proc = proc\n",
    "\n",
    "    def encodes(self, row):\n",
    "        cats,conts = (o.mapped(row.__getitem__) for o in (self.proc.cat_names,self.proc.cont_names))\n",
    "        return TensorTabular(tensor(cats).long(),tensor(conts).float())\n",
    "\n",
    "    def decodes(self, o):\n",
    "        to = TabularPandas(o, self.proc.cat_names, self.proc.cont_names, self.proc.y_names)\n",
    "        to = self.proc.decode(to)\n",
    "        return TabularLine(pd.Series({c: v for v,c in zip(to.items[0]+to.items[1], self.proc.cat_names+self.proc.cont_names)}))\n",
    "\n",
    "class ReadTabTarget(ItemTransform):\n",
    "    def __init__(self, proc): self.proc = proc\n",
    "    def encodes(self, row): return row[self.proc.y_names].astype(np.int64)\n",
    "    def decodes(self, o): return Category(self.proc.classes[self.proc.y_names][o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tds = TfmdDS(to.items, tfms=[[ReadTabLine(proc)], ReadTabTarget(proc)])\n",
    "# enc = tds[1]\n",
    "# test_eq(enc[0][0], tensor([2,1]))\n",
    "# test_close(enc[0][1], tensor([-0.628828]))\n",
    "# test_eq(enc[1], 1)\n",
    "\n",
    "# dec = tds.decode(enc)\n",
    "# assert isinstance(dec[0], TabularLine)\n",
    "# test_close(dec[0], pd.Series({'a': 1, 'b_na': False, 'b': 1}))\n",
    "# test_eq(dec[1], 'a')\n",
    "\n",
    "# test_stdout(lambda: print(tds.show_at(1)), \"\"\"a               1\n",
    "# b_na        False\n",
    "# b               1\n",
    "# category        a\n",
    "# dtype: object\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_torch_core.ipynb.\n",
      "Converted 01b_script.ipynb.\n",
      "Converted 01c_dataloader.ipynb.\n",
      "Converted 02_data_transforms.ipynb.\n",
      "Converted 03_data_pipeline.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_source.ipynb.\n",
      "Converted 07_vision_core.ipynb.\n",
      "Converted 08_pets_tutorial.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 11_layers.ipynb.\n",
      "Converted 11a_vision_models_xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_metrics.ipynb.\n",
      "Converted 21_tutorial_imagenette.ipynb.\n",
      "Converted 22_vision_learner.ipynb.\n",
      "Converted 23_tutorial_transfer_learning.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_text_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 50_data_block.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_utils_test.ipynb.\n",
      "Converted 96_data_external.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n",
      "Converted tmp.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
