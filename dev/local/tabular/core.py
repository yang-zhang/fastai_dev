#AUTOGENERATED! DO NOT EDIT! File to edit: dev/40_tabular_core.ipynb (unless otherwise specified).

__all__ = ['Tabular', 'TabularPandas', 'TabularProc', 'Categorify', 'Normalize', 'FillStrategy', 'FillMissing',
           'process_df', 'ReadTabBatch', 'TabDataLoader']

#Cell
from ..torch_basics import *
from ..test import *
from ..core import *
from ..data.all import *
from ..notebook.showdoc import show_doc

#Cell
pd.set_option('mode.chained_assignment','raise')

#Cell
class Tabular(CollBase):
    "A `DataFrame` wrapper that knows which cols are cont/cat/y, and returns rows in `__getitem__`"
    def __init__(self, df, cat_names=None, cont_names=None, y_names=None, is_y_cat=True, split=None):
        super().__init__(df)
        store_attr(self, 'y_names,is_y_cat,split')
        self.cat_names,self.cont_names = L(cat_names),L(cont_names)
        self.cat_y  = None if not is_y_cat else y_names
        self.cont_y = None if     is_y_cat else y_names

    def _new(self, df):
        return Tabular(df, self.cat_names, self.cont_names, self.y_names, is_y_cat=self.is_y_cat, split=self.split)

    def set_col(self,k,v): super().__setitem__(k, v)
    def show(self, max_n=10, **kwargs): display_df(self.all_cols[:max_n])

    def __getitem__(self, idxs):
        rows,cols = idxs if isinstance(idxs,tuple) else (idxs,None)
        f = self.items.columns.get_loc
        c = (slice(None) if cols is None
             else L(cols).mapped(f) if is_listy(cols)
             else f(cols))
        return self._new(self.items.iloc[rows, c])

    def __getattr__(self,k):
        if k.startswith('_') or k=='items': raise AttributeError
        return getattr(self.items,k)

#     @property
#     def __array__(self): return self.items.__array__
    @property
    def iloc(self): return self

    @property
    def targ(self): return self.items[self.y_names]
    @property
    def all_cont_names(self): return self.cont_names + self.cont_y
    @property
    def all_cat_names (self): return self.cat_names  + self.cat_y
    @property
    def all_col_names (self): return self.all_cont_names + self.all_cat_names

#Cell
class TabularPandas(Tabular):
    def transform(self, cols, f): self.set_col(cols, self[:,cols].transform(f))

#Cell
def _add_prop(cls, nm):
    prop = property(lambda o: o.items[list(getattr(o,nm+'_names'))])
    setattr(cls, nm+'s', prop)
    def _f(o,v): o.set_col(getattr(o,nm+'_names'), v)
    setattr(cls, nm+'s', prop.setter(_f))

_add_prop(Tabular, 'cat')
_add_prop(Tabular, 'all_cat')
_add_prop(Tabular, 'cont')
_add_prop(Tabular, 'all_cont')
_add_prop(Tabular, 'all_col')

#Cell
class TabularProc(InplaceTransform):
    "Base class to write a non-lazy tabular processor for dataframes"
    def setup(self, items=None):
        super().setup(items)
        # Procs are called as soon as data is available
        return self(items)

#Cell
class Categorify(TabularProc, CollBase):
    "Transform the categorical variables to that type."
    order = 1
    def __init__(self): self.items=[]
    def setups(self, to):
        to.classes = self.items = {n:CategoryMap(to[:to.split,n], add_na=True)
                                   for n in to.all_cat_names}

    def _apply_cats (self, c): return c.cat.codes+1 if is_categorical_dtype(c) else c.map(self[c.name].o2i)
    def _decode_cats(self, c): return c.map(dict(enumerate(self[c.name].items)))
    def encodes(self, to): to.transform(to.all_cat_names, self._apply_cats)
    def decodes(self, to): to.transform(to.all_cat_names, self._decode_cats)

#Cell
class Normalize(TabularProc):
    "Normalize the continuous variables."
    order = 2
    def setups(self, to):
        df = to[:to.split, to.cont_names]
        self.means,self.stds = df.mean(),df.std(ddof=0)+1e-7

    def encodes(self, to): to.conts = (to.conts-self.means) / self.stds
    def decodes(self, to): to.conts = (to.conts*self.stds ) + self.means

#Cell
class FillStrategy:
    "Namespace containing the various filling strategies."
    def median  (c,fill): return c.median()
    def constant(c,fill): return fill
    def mode    (c,fill): return c.dropna().value_counts().idxmax()

#Cell
class FillMissing(TabularProc):
    "Fill the missing values in continuous columns."
    def __init__(self, fill_strategy=FillStrategy.median, add_col=True, fill_vals=None):
        if fill_vals is None: fill_vals = defaultdict(int)
        store_attr(self, 'fill_strategy,add_col,fill_vals')

    def setups(self, to):
        df = to[:to.split, to.cont_names].items
        self.na_dict = {n:self.fill_strategy(df[n], self.fill_vals[n])
                        for n in pd.isnull(to.conts).any().keys()}

    def encodes(self, to):
        missing = pd.isnull(to.conts)
        for n in missing.any().keys():
            assert n in self.na_dict, f"nan values in `{n}` but not in setup training set"
            to[:,n].fillna(self.na_dict[n], inplace=True)
            if self.add_col:
                to.loc[:,n+'_na'] = missing[n]
                if n+'_na' not in to.cat_names: to.cat_names.append(n+'_na')

#Cell
@delegates(TabularPandas)
def process_df(df, procs, inplace=True, splits=None, **kwargs):
    "Process `df` with `procs` and returns the processed dataframe and the `TabularProcessor` associated"
    df = df if inplace else df.copy()
    if splits is not None: df = df.iloc[sum(splits, [])].reset_index(drop=True)
    split = None if splits is None else len(splits[0])
    to = TabularPandas(df, split=split, **kwargs)
    proc = Pipeline(procs)
    proc.setup(to)
    return to,proc

#Cell
class ReadTabBatch(ItemTransform):
    def __init__(self, proc): self.proc = proc
    def encodes(self, to): return (tensor(to.cats).long(),tensor(to.conts).float()), tensor(to.targ).long()

    def decodes(self, o):
        (cats,conts),targs = to_np(o)
        vals = np.concatenate([cats,conts,targs[:,None]], axis=1)
        df = pd.DataFrame(vals, columns=self.proc.cat_names+self.proc.cont_names+self.proc.y_names)
        to = TabularPandas(df, self.proc.cat_names, self.proc.cont_names, self.proc.y_names, is_y_cat=self.proc.cat_y is not None)
        to = self.proc.decode(to)
        return to

#Cell
@delegates()
class TabDataLoader(TfmdDL):
    do_item = noops
    def __init__(self, dataset, proc, bs=16, shuffle=False, after_batch=None, num_workers=0, **kwargs):
        after_batch = L(after_batch)+ReadTabBatch(proc)
        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)

    def create_batch(self, b): return self.dataset.items[b]