{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fastai/fastai_dev/blob/master/dev/08_pets_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.data.all import *\n",
    "from local.vision.core import *\n",
    "from local.notebook.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLs.PETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get image files and count dimension; most images are 3d but some are 2d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 9, 3: 7381})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = untar_data(URLs.PETS)/\"images\"\n",
    "items = get_image_files(source)\n",
    "item2ndim = {o:array(Image.open(o)).ndim for o in items}\n",
    "\n",
    "Counter(item2ndim.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_2d = [k for k,v in item2ndim.items() if v==2]\n",
    "items_3d = list(set(item2ndim.keys())-set(items_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 62,  44,  62, ..., 105, 105, 105],\n",
       "       [ 62,  62,  44, ...,  60,  60,  60],\n",
       "       [ 44,  62,  44, ...,  60, 196, 105],\n",
       "       ...,\n",
       "       [183, 223, 206, ...,  76, 181,  76],\n",
       "       [ 84, 209, 224, ..., 136,  76, 181],\n",
       "       [223, 183, 223, ...,  76,  76, 136]], dtype=uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(Image.open(items_2d[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 14,   4,   3],\n",
       "        [ 14,   4,   3],\n",
       "        [ 14,   4,   3],\n",
       "        ...,\n",
       "        [ 42,  29,  12],\n",
       "        [ 42,  29,  12],\n",
       "        [ 42,  29,  12]],\n",
       "\n",
       "       [[ 14,   4,   3],\n",
       "        [ 14,   4,   3],\n",
       "        [ 14,   4,   3],\n",
       "        ...,\n",
       "        [ 42,  29,  12],\n",
       "        [ 42,  29,  12],\n",
       "        [ 42,  29,  12]],\n",
       "\n",
       "       [[ 14,   4,   3],\n",
       "        [ 14,   4,   3],\n",
       "        [ 14,   4,   3],\n",
       "        ...,\n",
       "        [ 42,  29,  12],\n",
       "        [ 42,  29,  12],\n",
       "        [ 42,  29,  12]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[234, 226, 224],\n",
       "        [226, 218, 216],\n",
       "        [220, 212, 210],\n",
       "        ...,\n",
       "        [183, 175, 162],\n",
       "        [180, 176, 164],\n",
       "        [181, 179, 166]],\n",
       "\n",
       "       [[239, 231, 229],\n",
       "        [236, 228, 226],\n",
       "        [234, 226, 224],\n",
       "        ...,\n",
       "        [166, 158, 145],\n",
       "        [182, 178, 166],\n",
       "        [199, 197, 184]],\n",
       "\n",
       "       [[234, 226, 224],\n",
       "        [235, 227, 225],\n",
       "        [237, 229, 227],\n",
       "        ...,\n",
       "        [196, 188, 175],\n",
       "        [211, 207, 195],\n",
       "        [218, 216, 203]]], dtype=uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(Image.open(items_3d[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resized_image(fn:Path, sz=128):\n",
    "    x = Image.open(fn).resize((sz,sz))\n",
    "    # Convert image to tensor for modeling\n",
    "    return tensor(array(x)).permute(2,0,1).float()/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`resized_image` works fine for 3d arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [resized_image(o) for o in items_3d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but error on 2d arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-fb519d26debf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresized_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems_2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-4b2ef1648cbb>\u001b[0m in \u001b[0;36mresized_image\u001b[0;34m(fn, sz)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Convert image to tensor for modeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "resized_image(items_2d[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of 2d images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Egyptian_Mau_167.jpg',\n",
       " 'Egyptian_Mau_177.jpg',\n",
       " 'Egyptian_Mau_139.jpg',\n",
       " 'Egyptian_Mau_129.jpg',\n",
       " 'Abyssinian_34.jpg',\n",
       " 'Egyptian_Mau_191.jpg',\n",
       " 'staffordshire_bull_terrier_2.jpg',\n",
       " 'Egyptian_Mau_145.jpg',\n",
       " 'staffordshire_bull_terrier_22.jpg']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[os.path.basename(o) for o in items_2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Egyptian_Mau_167.jpg',\n",
       " 'Egyptian_Mau_177.jpg',\n",
       " 'Egyptian_Mau_139.jpg',\n",
       " 'Egyptian_Mau_129.jpg',\n",
       " 'Abyssinian_34.jpg',\n",
       " 'Egyptian_Mau_191.jpg',\n",
       " 'staffordshire_bull_terrier_2.jpg',\n",
       " 'Egyptian_Mau_145.jpg',\n",
       " 'staffordshire_bull_terrier_22.jpg']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[os.path.basename(o) for o in items_2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai_dev",
   "language": "python",
   "name": "fastai_dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
