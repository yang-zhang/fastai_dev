{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.all import *\n",
    "from local.tabular.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp tabular.rapids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular with rapids\n",
    "\n",
    "> Basic functions to preprocess tabular data before assembling it in a `DataBunch` on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "try: import cudf,nvcategory\n",
    "except: print(\"This requires rapids, see https://rapids.ai/ for installation details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def __array__(self:cudf.DataFrame): return self.pandas.__array__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularGPU(Tabular): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TabularProcessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _to_str(c): return c if c.dtype == \"object\" else c.astype(\"str\")\n",
    "def _remove_none(c):\n",
    "    if None in c: c.remove(None)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategorifyGPU(TabularProc, CollBase):\n",
    "    \"Transform the categorical variables to that type.\"\n",
    "    order = 1\n",
    "    def setups(self, to):\n",
    "        self.items = {n: nvcategory.from_strings(_to_str(to.loc[:to.split,n]).data).keys() for n in to.all_cat_names}\n",
    "        self.classes = to.classes = {n: CategoryMap(_remove_none(c.to_host()), add_na=True) for n,c in self.items.items()}\n",
    "    \n",
    "    def _apply_cats(self, c):\n",
    "        return cudf.Series(nvcategory.from_strings(_to_str(c).data).set_keys(self[c.name]).values()).add(1)\n",
    "    \n",
    "    def encodes(self, to): \n",
    "        for c in to.all_cat_names: to.set_col(c, self._apply_cats(to.items[c]))\n",
    "            \n",
    "    def _decode_cats(self, c): return c.map(dict(enumerate(self.classes[c.name].items)))\n",
    "    def decodes(self, to): to.transform(to.all_cat_names, self._decode_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"CategorifyGPU\" class=\"doc_header\"><code>class</code> <code>CategorifyGPU</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>CategorifyGPU</code>(**`enc`**=*`None`*, **`dec`**=*`None`*, **`filt`**=*`None`*, **`as_item`**=*`False`*) :: [`TabularProc`](/tabular.core.html#TabularProc)\n",
       "\n",
       "Transform the categorical variables to that type."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CategorifyGPU, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CategorifyGPU()\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,0,2]}))\n",
    "to = Tabular(df, 'a')\n",
    "\n",
    "cat.setup(to)\n",
    "test_eq(list(cat.items['a'].to_host()), ['0','1','2'])\n",
    "test_eq(df['a'].to_array(), np.array([1,2,3,1,3]))\n",
    "df1 = cudf.from_pandas(pd.DataFrame({'a':[1,0,3,-1,2]}))\n",
    "to1 = Tabular(df1, 'a')\n",
    "cat(to1)\n",
    "#Values that weren't in the training df are sent to 0 (na)\n",
    "test_eq(df1['a'].to_array(), np.array([2,1,0,0,3]))\n",
    "\n",
    "#Test decode\n",
    "to2 = Tabular(df1.to_pandas(), 'a')\n",
    "cat.decode(to2)\n",
    "test_eq(to2.a, np.array(['1','0','#na#','#na#','2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CategorifyGPU()\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,3,2]}))\n",
    "to = Tabular(df, 'a', split=3)\n",
    "cat.setup(to)\n",
    "test_eq(list(cat.items['a'].to_host()), [\"0\",\"1\",\"2\"])\n",
    "test_eq(df['a'].to_array(), np.array([1,2,3,0,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cudf.DataFrame ncols=1 nrows=4 >"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO Categorical\n",
    "cat = CategorifyGPU()\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True)}))\n",
    "to = Tabular(df, 'a')\n",
    "cat.setup(to)\n",
    "#Fails for now\n",
    "#test_eq(cat['a'].to_host(), ['H','M','L'])\n",
    "#test_eq(df[\"a\"].to_array(), [2,1,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NormalizeGPU(TabularProc):\n",
    "    \"Normalize the continuous variables.\"\n",
    "    order = 2\n",
    "    def setups(self, to):\n",
    "        self.means,self.stds = {},{}\n",
    "        for n in to.cont_names:\n",
    "            col = df.loc[:to.split,n]\n",
    "            self.means[n],self.stds[n] = col.mean(),col.std(ddof=0)+1e-7\n",
    "    \n",
    "    def encodes(self, to):\n",
    "        for n in to.cont_names: to.set_col(n, (to.items[n]-self.means[n])/self.stds[n])\n",
    "            \n",
    "    #def decodes(self, to):\n",
    "    #    for n in to.cont_names: to.set_col(n, (to.items[n]*self.stds[n])+self.means[n])\n",
    "    def decodes(self, to): to.conts = (to.conts*self.stds ) + self.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"NormalizeGPU\" class=\"doc_header\"><code>class</code> <code>NormalizeGPU</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>NormalizeGPU</code>(**`enc`**=*`None`*, **`dec`**=*`None`*, **`filt`**=*`None`*, **`as_item`**=*`False`*) :: [`TabularProc`](/tabular.core.html#TabularProc)\n",
       "\n",
       "Normalize the continuous variables."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(NormalizeGPU, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = NormalizeGPU()\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,3,4]}))\n",
    "to = Tabular(df, cont_names='a')\n",
    "norm.setup(to)\n",
    "x = np.array([0,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_eq(norm.means['a'], m)\n",
    "test_close(norm.stds['a'], s)\n",
    "test_close(df['a'].to_array(), (x-m)/s)\n",
    "df1 = cudf.from_pandas(pd.DataFrame({'a':[5,6,7]}))\n",
    "to1 = Tabular(df1, cont_names='a')\n",
    "norm(to1)\n",
    "test_close(df1['a'].to_array(), (np.array([5,6,7])-m)/s)\n",
    "to2 = Tabular(df1.to_pandas(), cont_names='a')\n",
    "to2 = norm.decode(to2)\n",
    "test_close(to2.a, [5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = NormalizeGPU()\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,3,4]}))\n",
    "to = Tabular(df, cont_names='a', split=3)\n",
    "norm.setup(to)\n",
    "x = np.array([0,1,2])\n",
    "m,s = x.mean(),x.std()\n",
    "test_eq(norm.means, {'a': m})\n",
    "test_close(norm.stds['a'], s)\n",
    "test_close(df['a'].to_array(), (np.array([0,1,2,3,4])-m)/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_median(col):\n",
    "    \"Get the median of a cudf Series `col`\"\n",
    "    col = col.dropna().reset_index(drop=True)\n",
    "    return col.sort_values()[len(col)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FillStrategyGPU:\n",
    "    \"Namespace containing the various filling strategies.\"\n",
    "    def median  (c,fill): return get_median(c)\n",
    "    def constant(c,fill): return fill\n",
    "    def mode    (c,fill): return c.dropna().value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FillMissingGPU(TabularProc):\n",
    "    \"Fill the missing values in continuous columns.\"\n",
    "    def __init__(self, fill_strategy=FillStrategyGPU.median, add_col=True, fill_vals=None):\n",
    "        if fill_vals is None: fill_vals = defaultdict(int)\n",
    "        store_attr(self, 'fill_strategy,add_col,fill_vals')\n",
    "\n",
    "    def setups(self, to):\n",
    "        self.na_dict = {}\n",
    "        for n in to.cont_names:\n",
    "            col = to.loc[:to.split, n]\n",
    "            if col.isnull().any(): self.na_dict[n] = self.fill_strategy(col, self.fill_vals[n])\n",
    "\n",
    "    def encodes(self, to):\n",
    "        for n in to.cont_names:\n",
    "            if n in self.na_dict:\n",
    "                if self.add_col:\n",
    "                    to.items[n+'_na'] = to.items[n].isnull()\n",
    "                    if n+'_na' not in to.cat_names: to.cat_names.append(n+'_na')\n",
    "                to.set_col(n, to.items[n].fillna(self.na_dict[n]))\n",
    "            elif df[n].isnull().any():\n",
    "                raise Exception(f\"nan values in `{n}` but not in setup training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"FillMissingGPU\" class=\"doc_header\"><code>class</code> <code>FillMissingGPU</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>FillMissingGPU</code>(**`fill_strategy`**=*`'median'`*, **`add_col`**=*`True`*, **`fill_vals`**=*`None`*) :: [`TabularProc`](/tabular.core.html#TabularProc)\n",
       "\n",
       "Fill the missing values in continuous columns."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FillMissingGPU, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill1,fill2,fill3 = (FillMissingGPU(fill_strategy=s) \n",
    "                     for s in [FillStrategyGPU.median, FillStrategyGPU.constant, FillStrategyGPU.mode])\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,np.nan,1,2,3,4]}))\n",
    "df1 = df.copy(); df2 = df.copy()\n",
    "to,to1,to2 = Tabular(df, cont_names='a'),Tabular(df1, cont_names='a'),Tabular(df2, cont_names='a')\n",
    "fill1.setup(to); fill2.setup(to1); fill3.setup(to2)\n",
    "test_eq(fill1.na_dict, {'a': 2.})\n",
    "test_eq(fill2.na_dict, {'a': 0})\n",
    "test_eq(fill3.na_dict, {'a': 1.0})\n",
    "\n",
    "for t in [to, to1, to2]: test_eq(t.cat_names, ['a_na'])\n",
    "\n",
    "for to_,v in zip([to, to1, to2], [2., 0., 1.]):\n",
    "    test_eq(to_.items['a'].to_array(), np.array([0, 1, v, 1, 2, 3, 4]))\n",
    "    test_eq(to_.items['a_na'].to_array(), np.array([0, 0, 1, 0, 0, 0, 0]))\n",
    "    \n",
    "dfa = cudf.from_pandas(pd.DataFrame({'a':[np.nan,0,np.nan]}))\n",
    "dfa1 = dfa.copy(); dfa2 = dfa.copy()\n",
    "to,to1,to2 = Tabular(dfa, cont_names='a'),Tabular(dfa1, cont_names='a'),Tabular(dfa2, cont_names='a')\n",
    "fill1(to); fill2(to1); fill3(to2)\n",
    "for to_,v in zip([to, to1, to2], [2., 0., 1.]):\n",
    "    test_eq(to_.items['a'].to_array(), np.array([v, 0, v]))\n",
    "    test_eq(to_.items['a_na'].to_array(), np.array([1, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Pipelines -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [NormalizeGPU(), CategorifyGPU(), FillMissingGPU(), noop]\n",
    "proc = Pipeline(procs)\n",
    "\n",
    "#Test reordering and partialize\n",
    "test_eq(L(proc.fs).mapped(type), [FillMissingGPU, Transform, CategorifyGPU, NormalizeGPU])\n",
    "\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4]}))\n",
    "to = Tabular(df, 'a', 'b')\n",
    "\n",
    "#Test setup and apply on df_trn\n",
    "proc.setup(to)\n",
    "test_eq(to.items['a'].to_array(), [1,2,3,2,2,3,1])\n",
    "test_eq(to.items['b_na'].to_array(), [1,1,2,1,1,1,1])\n",
    "x = np.array([0,1,2,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_close(to.items['b'].to_array(), (x-m)/s)\n",
    "test_eq(proc.classes, {'a': ['#na#','0','1','2'], 'b_na': ['#na#','False','True']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test apply on y_names\n",
    "procs = [NormalizeGPU(), CategorifyGPU(), FillMissingGPU(), noop]\n",
    "proc = Pipeline(procs)\n",
    "\n",
    "df = cudf.from_pandas(pd.DataFrame({'a':[0,1,2,1,1,2,0], 'b':[0,1,np.nan,1,2,3,4], 'c': ['b','a','b','a','a','b','a']}))\n",
    "to = Tabular(df, 'a', 'b', y_names='c')\n",
    "\n",
    "proc.setup(to)\n",
    "test_eq(to.cat_names, ['a', 'b_na'])\n",
    "test_eq(to.items['a'].to_array(), [1,2,3,2,2,3,1])\n",
    "test_eq(to.items['b_na'].to_array(), [1,1,2,1,1,1,1])\n",
    "test_eq(to.items['c'].to_array(), [2,1,2,1,1,2,1])\n",
    "x = np.array([0,1,2,1,2,3,4])\n",
    "m,s = x.mean(),x.std()\n",
    "test_close(to.items['b'].to_array(), (x-m)/s)\n",
    "test_eq(proc.classes, {'a': ['#na#','0','1','2'], 'b_na': ['#na#','False','True'], 'c': ['#na#','a','b']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the same `splits` as you will use for splitting the data, so that the setup is only done on the training set. `cat_names` are the names of the categorical variables, `cont_names` the continous ones, `cat_y` are the names of the dependent variables that are categories. If `inplace=True`, processing is applied inplace, otherwis it creates a copy of `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "\n",
    "class ReadTabBatchGPU(ItemTransform):\n",
    "    def __init__(self, proc): self.proc = proc\n",
    "\n",
    "    def encodes(self, to):\n",
    "        return (from_dlpack(to.cats.to_dlpack()).long(),from_dlpack(to.conts.to_dlpack()).float()), from_dlpack(to.targ.to_dlpack()).long()\n",
    "\n",
    "    def decodes(self, o):\n",
    "        (cats,conts),targs = to_np(o)\n",
    "        df = pd.DataFrame({**{c: cats [:,i] for i,c in enumerate(self.proc.cat_names )},\n",
    "                           **{c: conts[:,i] for i,c in enumerate(self.proc.cont_names)},\n",
    "                           self.proc.y_names: targs})\n",
    "        to = Tabular(df, self.proc.cat_names, self.proc.cont_names, self.proc.y_names, is_y_cat=self.proc.cat_y is not None)\n",
    "        to = self.proc.decode(to)\n",
    "        return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates()\n",
    "class TabDataLoaderGPU(TfmdDL):\n",
    "    do_item = noops\n",
    "    def __init__(self, dataset, proc, bs=16, shuffle=False, after_batch=None, num_workers=0, **kwargs):\n",
    "        after_batch = L(after_batch)+ReadTabBatchGPU(proc)\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)\n",
    "\n",
    "    def create_batch(self, b): return self.dataset.items[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cudf.DataFrame ncols=15 nrows=5 >"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = cudf.from_pandas(pd.read_csv(path/'adult.csv'))\n",
    "df_trn,df_tst = df.iloc[:10000].copy(),df.iloc[10000:].copy()\n",
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [CategorifyGPU(), FillMissingGPU(), NormalizeGPU()]\n",
    "\n",
    "splits = RandomSplitter()(range_of(df_trn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 270 ms, sys: 8.39 ms, total: 278 ms\n",
      "Wall time: 277 ms\n"
     ]
    }
   ],
   "source": [
    "%time to,proc = process_df(df_trn, procs, splits=splits, cat_names=cat_names, cont_names=cont_names, y_names=\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filts = [list(range(len(splits[0]))), list(range(len(splits[0]), 10000))]\n",
    "dsrc = DataSource(to, filts=filts, tfms=[None])\n",
    "dl = TabDataLoaderGPU(dsrc.valid, proc, bs=64, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sgugger/anaconda3/lib/python3.7/site-packages/cudf/io/dlpack.py:83: UserWarning: WARNING: cuDF to_dlpack() produces column-major (Fortran order) output. If the output tensor needs to be row major, transpose the output of this function.\n",
      "  return cpp_dlpack.to_dlpack(gdf_cols)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>153926.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>?</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>75167.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>254973.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>379118.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.0</td>\n",
       "      <td>34007.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.0</td>\n",
       "      <td>301911.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63.0</td>\n",
       "      <td>137192.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>197496.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63.0</td>\n",
       "      <td>188914.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40.0</td>\n",
       "      <td>196029.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not working yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dsrc = DataSource(df1, filts=splits, tfms=[[ReadTabLine(proc)], [ReadTabTarget(proc)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbch = dsrc.databunch(bs=64)\n",
    "#dbch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
