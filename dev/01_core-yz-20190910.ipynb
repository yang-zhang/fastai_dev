{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.test import *\n",
    "from local.imports import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "if torch.cuda.is_available(): torch.cuda.set_device(int(os.environ.get('DEFAULT_GPU') or 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Basic functions used in the fastai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "defaults = SimpleNamespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "types.SimpleNamespace"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PrePostInitMeta(type):\n",
    "    \"A metaclass that calls optional `__pre_init__` and `__post_init__` methods\"\n",
    "    def __new__(cls, name, bases, dct):\n",
    "        x = super().__new__(cls, name, bases, dct)\n",
    "        def _pass(self, *args,**kwargs): pass\n",
    "        for o in ('__init__', '__pre_init__', '__post_init__'):\n",
    "            if not hasattr(x,o): setattr(x,o,_pass)\n",
    "        old_init = x.__init__\n",
    "        \n",
    "        @functools.wraps(old_init)\n",
    "        def _init(self,*args,**kwargs):\n",
    "            self.__pre_init__()\n",
    "            old_init(self, *args,**kwargs)\n",
    "            self.__post_init__()\n",
    "        setattr(x, '__init__', _init)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"PrePostInitMeta\" class=\"doc_header\"><code>class</code> <code>PrePostInitMeta</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#Metaclasses\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>PrePostInitMeta</code>(**`name`**, **`bases`**, **`dct`**) :: `type`\n",
       "\n",
       "A metaclass that calls optional `__pre_init__` and `__post_init__` methods"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(PrePostInitMeta, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _T(metaclass=PrePostInitMeta):\n",
    "    def __pre_init__(self):  self.a  = 0; assert self.a==0\n",
    "    def __init__(self):      self.a += 1; assert self.a==1\n",
    "    def __post_init__(self): self.a += 1; assert self.a==2\n",
    "\n",
    "t = _T()\n",
    "t.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseObj(metaclass=PrePostInitMeta):\n",
    "    \"Base class that provides `PrePostInitMeta` metaclass to subclasses\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _T(BaseObj):\n",
    "    def __pre_init__(self):  self.a  = 0; assert self.a==0\n",
    "    def __init__(self):      self.a += 1; assert self.a==1\n",
    "    def __post_init__(self): self.a += 1; assert self.a==2\n",
    "\n",
    "t = _T()\n",
    "t.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NewChkMeta(PrePostInitMeta):\n",
    "    \"Metaclass to avoid recreating object passed to constructor (plus all `PrePostInitMeta` functionality)\"\n",
    "    def __new__(cls, name, bases, dct):\n",
    "        x = super().__new__(cls, name, bases, dct)\n",
    "        old_init,old_new = x.__init__,x.__new__\n",
    "\n",
    "        @functools.wraps(old_init)\n",
    "        def _new(cls, x=None, *args, **kwargs):\n",
    "            if x is not None and isinstance(x,cls):\n",
    "                x._newchk = 1\n",
    "                return x\n",
    "            res = old_new(cls)\n",
    "            res._newchk = 0\n",
    "            return res\n",
    "\n",
    "        @functools.wraps(old_init)\n",
    "        def _init(self,*args,**kwargs):\n",
    "            if self._newchk: return\n",
    "            old_init(self, *args, **kwargs)\n",
    "\n",
    "        x.__init__,x.__new__ = _init,_new\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(metaclass=NewChkMeta):\n",
    "    \"Testing\"\n",
    "    def __init__(self, o=None): self.foo = getattr(o,'foo',0) + 1\n",
    "\n",
    "class _T2():\n",
    "    def __init__(self, o): self.foo = getattr(o,'foo',0) + 1\n",
    "\n",
    "t = _T(1)\n",
    "test_eq(t.foo,1)\n",
    "t2 = _T(t)\n",
    "test_eq(t2.foo,1)\n",
    "test_is(t,t2)\n",
    "\n",
    "t = _T2(1)\n",
    "test_eq(t.foo,1)\n",
    "t2 = _T2(t)\n",
    "test_eq(t2.foo,2)\n",
    "\n",
    "test_eq(_T.__doc__, \"Testing\")\n",
    "test_eq(str(inspect.signature(_T)), '(o=None)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BypassNewMeta(type):\n",
    "    \"Metaclass: casts `x` to this class, initializing with `_new_meta` if available\"\n",
    "    def __call__(cls, x, *args, **kwargs):\n",
    "        if hasattr(cls, '_new_meta'): x = cls._new_meta(x, *args, **kwargs)\n",
    "        if cls!=x.__class__: x.__class__ = cls\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T0: pass\n",
    "class _T(T0, metaclass=BypassNewMeta): pass\n",
    "\n",
    "t = T0()\n",
    "t.a = 1\n",
    "t2 = _T(t)\n",
    "test_eq(type(t2), _T)\n",
    "test_eq(t2.a,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundational functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def patch_to(cls, as_prop=False):\n",
    "    \"Decorator: add `f` to `cls`\"\n",
    "    def _inner(f):\n",
    "        nf = copy(f)\n",
    "        # `functools.update_wrapper` when passing patched function to `Pipeline`, so we do it manually\n",
    "        for o in functools.WRAPPER_ASSIGNMENTS: setattr(nf, o, getattr(f,o))\n",
    "        nf.__qualname__ = f\"{cls.__name__}.{f.__name__}\"\n",
    "        setattr(cls, f.__name__, property(nf) if as_prop else nf)\n",
    "        return f\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T3(int): pass\n",
    "\n",
    "@patch_to(_T3)\n",
    "def func1(x, a): return x+a\n",
    "\n",
    "t = _T3(1)\n",
    "test_eq(t.func1(2), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def patch(f):\n",
    "    \"Decorator: add `f` to the first parameter's class (based on f's type annotations)\"\n",
    "    cls = next(iter(f.__annotations__.values()))\n",
    "    return patch_to(cls)(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def func(x:_T3, a):\n",
    "    \"test\"\n",
    "    return x+2\n",
    "\n",
    "t = _T3(1)\n",
    "test_eq(t.func(2), 3)\n",
    "test_eq(t.func.__qualname__, '_T3.func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def patch_property(f):\n",
    "    \"Decorator: add `f` as a property to the first parameter's class (based on f's type annotations)\"\n",
    "    cls = next(iter(f.__annotations__.values()))\n",
    "    return patch_to(cls, as_prop=True)(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_property\n",
    "def prop(x:_T3): return x+1\n",
    "\n",
    "t = _T3(1)\n",
    "test_eq(t.prop, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _mk_param(n,d=None): return inspect.Parameter(n, inspect.Parameter.KEYWORD_ONLY, default=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sig(f, b): test_eq(str(inspect.signature(f)), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def use_kwargs(names, keep=False):\n",
    "    \"Decorator: replace `**kwargs` in signature with `names` params\"\n",
    "    def _f(f):\n",
    "        sig = inspect.signature(f)\n",
    "        sigd = dict(sig.parameters)\n",
    "        k = sigd.pop('kwargs')\n",
    "        s2 = {n:_mk_param(n) for n in names if n not in sigd}\n",
    "        sigd.update(s2)\n",
    "        if keep: sigd['kwargs'] = k\n",
    "        f.__signature__ = sig.replace(parameters=sigd.values())\n",
    "        return f\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_kwargs(['y', 'z'])\n",
    "def foo(a, b=1, **kwargs): pass\n",
    "test_sig(foo, '(a, b=1, *, y=None, z=None)')\n",
    "\n",
    "@use_kwargs(['y', 'z'], keep=True)\n",
    "def foo(a, *args, b=1, **kwargs): pass\n",
    "test_sig(foo, '(a, *args, b=1, y=None, z=None, **kwargs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def delegates(to=None, keep=False):\n",
    "    \"Decorator: replace `**kwargs` in signature with params from `to`\"\n",
    "    def _f(f):\n",
    "        if to is None: to_f,from_f = f.__base__.__init__,f.__init__\n",
    "        else:          to_f,from_f = to,f\n",
    "        sig = inspect.signature(from_f)\n",
    "        sigd = dict(sig.parameters)\n",
    "        k = sigd.pop('kwargs')\n",
    "        s2 = {k:v for k,v in inspect.signature(to_f).parameters.items()\n",
    "              if v.default != inspect.Parameter.empty and k not in sigd}\n",
    "        sigd.update(s2)\n",
    "        if keep: sigd['kwargs'] = k\n",
    "        from_f.__signature__ = sig.replace(parameters=sigd.values())\n",
    "        return f\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basefoo(e, c=2): pass\n",
    "\n",
    "@delegates(basefoo)\n",
    "def foo(a, b=1, **kwargs): pass\n",
    "test_sig(foo, '(a, b=1, c=2)')\n",
    "\n",
    "@delegates(basefoo, keep=True)\n",
    "def foo(a, b=1, **kwargs): pass\n",
    "test_sig(foo, '(a, b=1, c=2, **kwargs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFoo:\n",
    "    def __init__(self, e, c=2): pass\n",
    "\n",
    "@delegates()\n",
    "class Foo(BaseFoo):\n",
    "    def __init__(self, a, b=1, **kwargs): super().__init__(**kwargs)\n",
    "\n",
    "test_sig(Foo, '(a, b=1, c=2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def funcs_kwargs(cls):\n",
    "    \"Replace methods in `self._methods` with those from `kwargs`\"\n",
    "    old_init = cls.__init__\n",
    "    def _init(self, *args, **kwargs):\n",
    "        for k in cls._methods:\n",
    "            arg = kwargs.pop(k,None)\n",
    "            if arg is not None:\n",
    "                if isinstance(arg,types.MethodType): arg = types.MethodType(arg.__func__, self)\n",
    "                setattr(self, k, arg)\n",
    "        old_init(self, *args, **kwargs)\n",
    "    functools.update_wrapper(_init, old_init)\n",
    "    cls.__init__ = use_kwargs(cls._methods)(_init)\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def method(f):\n",
    "    \"Mark `f` as a method\"\n",
    "    # `1` is a dummy instance since Py3 doesn't allow `None` any more\n",
    "    return types.MethodType(f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@funcs_kwargs\n",
    "class T:\n",
    "    _methods=['b']\n",
    "    def __init__(self, f=1, **kwargs): assert not kwargs\n",
    "    def a(self): return 1\n",
    "    def b(self): return 2\n",
    "    \n",
    "t = T()\n",
    "test_eq(t.a(), 1)\n",
    "test_eq(t.b(), 2)\n",
    "t = T(b = lambda:3)\n",
    "test_eq(t.b(), 3)\n",
    "test_sig(T, '(f=1, *, b=None)')\n",
    "test_fail(lambda: T(a = lambda:3))\n",
    "\n",
    "@method\n",
    "def _f(self,a=1): return a+1\n",
    "t = T(b = _f)\n",
    "test_eq(t.b(2), 3)\n",
    "\n",
    "class T2(T):\n",
    "    def __init__(self,a):\n",
    "        super().__init__(b = lambda:3)\n",
    "        self.a=a\n",
    "t = T2(a=1)\n",
    "test_eq(t.b(), 3)\n",
    "test_sig(T2, '(a)')\n",
    "\n",
    "def _g(a=1): return a+1\n",
    "class T3(T): b = staticmethod(_g)\n",
    "t = T3()\n",
    "test_eq(t.b(2), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime type checking is handy, so let's make it easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "#NB: Please don't move this to a different line or module, since it's used in testing `get_source_link`\n",
    "def chk(f): return typechecked(always=True)(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorator for a function to check that type-annotated arguments receive arguments of the right type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chk\n",
    "def test_chk(a:int=1): return a\n",
    "\n",
    "test_eq(test_chk(2), 2)\n",
    "test_eq(test_chk(), 1)\n",
    "test_fail(lambda: test_chk('a'), contains='\"a\" must be int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorated functions will pickle correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pickle.loads(pickle.dumps(test_chk))\n",
    "test_eq(t(2), 2)\n",
    "test_eq(t(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def working_directory(path):\n",
    "    \"Change working directory to `path` and return to previous on exit.\"\n",
    "    prev_cwd = Path.cwd()\n",
    "    os.chdir(path)\n",
    "    try: yield\n",
    "    finally: os.chdir(prev_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monkey-patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_listy(x): return isinstance(x,(list,tuple,Generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tensor(x, *rest, **kwargs):\n",
    "    \"Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.\"\n",
    "    if len(rest): x = (x,)+rest\n",
    "    # Pytorch bug in dataloader using num_workers>0\n",
    "    if isinstance(x, (tuple,list)) and len(x)==0: return tensor(0)\n",
    "    res = (torch.tensor(x, **kwargs) if isinstance(x, (tuple,list))\n",
    "           else as_tensor(x, **kwargs) if hasattr(x, '__array__')\n",
    "           else as_tensor(x, **kwargs) if is_listy(x)\n",
    "           else as_tensor(x, **kwargs) if is_iter(x)\n",
    "           else None)\n",
    "    if res is None:\n",
    "        res = as_tensor(array(x), **kwargs)\n",
    "        if res.dtype is torch.float64: return res.float()\n",
    "    if res.dtype is torch.int32:\n",
    "        warn('Tensor is int32: upgrading to int64; for better performance use int64 input')\n",
    "        return res.long()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tensor(array([1,2,3])), torch.tensor([1,2,3]))\n",
    "test_eq(tensor(1,2,3), torch.tensor([1,2,3]))\n",
    "test_eq_type(tensor(1.0), torch.tensor(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "#### `Tensor.ndim`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an `ndim` property to `Tensor` with same semantics as [numpy ndim](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.ndim.html), which allows tensors to be used in matplotlib and other places that assume this property exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(torch.tensor([1,2]).ndim,1)\n",
    "test_eq(torch.tensor(1).ndim,0)\n",
    "test_eq(torch.tensor([[1]]).ndim,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "def add_docs(cls, cls_doc=None, **docs):\n",
    "    \"Copy values from `docs` to `cls` docstrings, and confirm all public methods are documented\"\n",
    "    if cls_doc is not None: cls.__doc__ = cls_doc\n",
    "    for k,v in docs.items():\n",
    "        f = getattr(cls,k)\n",
    "        if hasattr(f,'__func__'): f = f.__func__ # required for class methods\n",
    "        f.__doc__ = v\n",
    "    # List of public callables without docstring\n",
    "    nodoc = [c for n,c in vars(cls).items() if isinstance(c,Callable)\n",
    "             and not n.startswith('_') and c.__doc__ is None]\n",
    "    assert not nodoc, f\"Missing docs: {nodoc}\"\n",
    "    assert cls.__doc__ is not None, f\"Missing class docs: {cls}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "def docs(cls):\n",
    "    \"Decorator version of `add_docs`, using `_docs` dict\"\n",
    "    add_docs(cls, **cls._docs)\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T:\n",
    "    def f(self): pass\n",
    "    @classmethod\n",
    "    def g(cls): pass\n",
    "add_docs(_T, \"a\", f=\"f\", g=\"g\")\n",
    "\n",
    "test_eq(_T.__doc__, \"a\")\n",
    "test_eq(_T.f.__doc__, \"f\")\n",
    "test_eq(_T.g.__doc__, \"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def custom_dir(c, add:List):\n",
    "    \"Implement custom `__dir__`, adding `add` to `cls`\"\n",
    "    return dir(type(c)) + list(c.__dict__.keys()) + add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"is_iter\" class=\"doc_header\"><code>is_iter</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/local/imports.py#L49\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>is_iter</code>(**`o`**)\n",
       "\n",
       "Test whether `o` can be used in a `for` loop"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(is_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_iter([1])\n",
    "assert not is_iter(torch.tensor(1))\n",
    "assert is_iter(torch.tensor([1,2]))\n",
    "assert (o for o in range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GetAttr -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GetAttr(BaseObj):\n",
    "    \"Inherit from this to have all attr accesses in `self._xtra` passed down to `self.default`\"\n",
    "    @property\n",
    "    def _xtra(self): return [o for o in dir(self.default) if not o.startswith('_')]\n",
    "    def __getattr__(self,k):\n",
    "        if k not in ('_xtra','default') and k in self._xtra: return getattr(self.default, k)\n",
    "        raise AttributeError(k)\n",
    "    def __dir__(self): return custom_dir(self, self._xtra)\n",
    "    def __setstate__(self,data): self.__dict__.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _C(GetAttr):\n",
    "    _xtra = ['lower']\n",
    "    def __init__(self,a): self.default = a\n",
    "    def foo(self): noop\n",
    "\n",
    "t = _C('hi')\n",
    "test_eq(t.lower(), 'hi')\n",
    "test_fail(lambda: t.upper())\n",
    "assert 'lower' in dir(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def delegate_attr(self, k, to):\n",
    "    \"Use in `__getattr__` to delegate to attr `to` without inheriting from `GetAttr`\"\n",
    "    if k.startswith('_') or k==to: raise AttributeError(k)\n",
    "    try: return getattr(getattr(self,to), k)\n",
    "    except AttributeError: raise AttributeError(k) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _C:\n",
    "    f = 'Hi'\n",
    "    def __getattr__(self, k): return delegate_attr(self, k, 'f')\n",
    "\n",
    "t = _C()\n",
    "test_eq(t.lower(), 'hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def coll_repr(c, max_n=10):\n",
    "    \"String repr of up to `max_n` items of (possibly lazy) collection `c`\"\n",
    "    return f'(#{len(c)}) [' + ','.join(itertools.islice(map(str,c), max_n)) + (\n",
    "        '...' if len(c)>10 else '') + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(coll_repr(range(1000), 5), '(#1000) [0,1,2,3,4...]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def mask2idxs(mask):\n",
    "    \"Convert bool mask or index list to index `L`\"\n",
    "    mask = list(mask)\n",
    "    if len(mask)==0: return []\n",
    "    if isinstance(mask[0],bool): return [i for i,m in enumerate(mask) if m]\n",
    "    return [int(i) for i in mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(mask2idxs([False,True,False,True]), [1,3])\n",
    "test_eq(mask2idxs(torch.tensor([1,2,3])), [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, (str,np.ndarray,Tensor)): return [o]\n",
    "    if is_iter(o): return list(o)\n",
    "    return [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CollBase:\n",
    "    \"Base class for composing a list of `items`\"\n",
    "    _xtra =  [o for o in dir([]) if not o.startswith('_')]\n",
    "\n",
    "    def __init__(self, items): self.items = items\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self, k): return self.items[k]\n",
    "    def __setitem__(self, k, v): self.items[k] = v\n",
    "    def __delitem__(self, i): del(self.items[i])\n",
    "    def __repr__(self): return self.items.__repr__()\n",
    "    def __iter__(self): return self.items.__iter__()\n",
    "    def _new(self, items, *args, **kwargs): return self.__class__(items, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cycle(o):\n",
    "    \"Like `itertools.cycle` except creates list of `None`s if `o` is empty\"\n",
    "    return itertools.cycle(o) if o is not None and len(o) > 0 else itertools.cycle([None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(itertools.islice(cycle('abc'),5), 'abcab')\n",
    "test_eq(itertools.islice(cycle([]),3), [None]*3)\n",
    "test_eq(itertools.islice(cycle(None),3), [None]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def zip_cycle(x, *args):\n",
    "    \"Like `itertools.zip_longest` but `cycle`s through elements of all but first argument\"\n",
    "    return zip(x, *map(cycle,args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(zip_cycle([1,2,3,4],'abc'), [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'a')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class L(CollBase, GetAttr, metaclass=NewChkMeta):\n",
    "    \"Behaves like a list of `items` but can also index with list of indices or masks\"\n",
    "    def __init__(self, items=None, *rest, use_list=False, match=None):\n",
    "        if rest: items = (items,)+rest\n",
    "        if items is None: items = []\n",
    "        if (use_list is not None) or not isinstance(items,(Tensor,ndarray,pd.DataFrame,pd.Series)):\n",
    "            items = list(items) if use_list else _listify(items)\n",
    "        if match is not None:\n",
    "            if len(items)==1: items = items*len(match)\n",
    "            else: assert len(items)==len(match), 'Match length mismatch'\n",
    "        super().__init__(items)\n",
    "        \n",
    "    def __getitem__(self, idx): return L(self._gets(idx), use_list=None) if is_iter(idx) else self._get(idx)\n",
    "    def _get(self, i): return getattr(self.items,'iloc',self.items)[i]\n",
    "    def _gets(self, i):\n",
    "        i = mask2idxs(i)\n",
    "        return (self.items.iloc[list(i)] if hasattr(self.items,'iloc')\n",
    "                else self.items.__array__()[(i,)] if hasattr(self.items,'__array__')\n",
    "                else [self.items[i_] for i_ in i])\n",
    "    \n",
    "    def __setitem__(self, idx, o):\n",
    "        \"Set `idx` (can be list of indices, or mask, or int) items to `o` (which is broadcast if not iterable)\"\n",
    "        idx = idx if isinstance(idx,L) else _listify(idx) \n",
    "        if not is_iter(o): o = [o]*len(idx)\n",
    "        for i,o_ in zip(idx,o): self.items[i] = o_\n",
    "    \n",
    "    @property\n",
    "    def default(self): return self.items\n",
    "    def __iter__(self): return (self[i] for i in range(len(self)))\n",
    "    def __repr__(self): return coll_repr(self)\n",
    "    def __eq__(self,b): return all_equal(b,self)\n",
    "    def __invert__(self): return self._new(not i for i in self)\n",
    "    def __mul__ (a,b): return a._new(a.items*b)\n",
    "    def __add__ (a,b): return a._new(a.items+_listify(b))\n",
    "    def __radd__(a,b): return a._new(b)+a\n",
    "    def __addi__(a,b):\n",
    "        a.items += list(b)\n",
    "        return a\n",
    "\n",
    "    def sorted(self, key=None, reverse=False):\n",
    "        \"New `L` sorted by `key`. If key is str then use `attrgetter`. If key is int then use `itemgetter`.\"\n",
    "        if isinstance(key,str):   k=lambda o:getattr(o,key,0)\n",
    "        elif isinstance(key,int): k=itemgetter(key)\n",
    "        else: k=key\n",
    "        return self._new(sorted(self.items, key=k, reverse=reverse))\n",
    "    \n",
    "    @classmethod\n",
    "    def range(cls, a, b=None, step=None):\n",
    "        \"Same as builtin `range`, but returns an `L`. Can pass a collection for `a`, to use `len(a)`\"\n",
    "        if is_coll(a): a = len(a)\n",
    "        return cls(range(a,b,step) if step is not None else range(a,b) if b is not None else range(a))\n",
    "    \n",
    "    def unique(self): return L(dict.fromkeys(self).keys())\n",
    "    def val2idx(self): return {v:k for k,v in enumerate(self)}\n",
    "    def itemgot(self, idx): return self.mapped(itemgetter(idx))\n",
    "    def attrgot(self, k, default=None): return self.mapped(lambda o:getattr(o,k,default))\n",
    "    def tensored(self): return self.mapped(tensor)\n",
    "    def stack(self, dim=0): return torch.stack(list(self.tensored()), dim=dim)\n",
    "    def cat  (self, dim=0): return torch.cat  (list(self.tensored()), dim=dim)\n",
    "    def cycle(self): return cycle(self)\n",
    "    def filtered(self, f, *args, **kwargs): return self._new(filter(partial(f,*args,**kwargs), self))\n",
    "    def mapped(self, f, *args, **kwargs): return self._new(map(partial(f,*args,**kwargs), self))\n",
    "    def mapped_dict(self, f, *args, **kwargs): return {k:f(k, *args,**kwargs) for k in self}\n",
    "    def starmapped(self, f, *args, **kwargs): return self._new(itertools.starmap(partial(f,*args,**kwargs), self))\n",
    "    def zipped(self, cycled=False): return self._new((zip_cycle if cycled else zip)(*self))\n",
    "    def zipwith(self, *rest, cycled=False): return self._new([self, *rest]).zipped(cycled=cycled)\n",
    "    def mapped_zip(self, f, cycled=False): return self.zipped(cycled=cycled).starmapped(f)\n",
    "    def mapped_zipwith(self, f, *rest, cycled=False): return self.zipwith(*rest, cycled=cycled).starmapped(f)\n",
    "    def shuffled(self):\n",
    "        it = copy(self.items)\n",
    "        random.shuffle(it)\n",
    "        return self._new(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "add_docs(L,\n",
    "         __getitem__=\"Retrieve `idx` (can be list of indices, or mask, or int) items\",\n",
    "         unique=\"Unique items, in stable order\",\n",
    "         val2idx=\"Dict from value to index\",\n",
    "         filtered=\"Create new `L` filtered by predicate `f`, passing `args` and `kwargs` to `f`\",\n",
    "         mapped=\"Create new `L` with `f` applied to all `items`, passing `args` and `kwargs` to `f`\",\n",
    "         mapped_dict=\"Like `mapped`, but creates a dict from `items` to function results\",\n",
    "         starmapped=\"Like `mapped`, but use `itertools.starmap`\",\n",
    "         itemgot=\"Create new `L` with item `idx` of all `items`\",\n",
    "         attrgot=\"Create new `L` with attr `k` of all `items`\",\n",
    "         tensored=\"`mapped(tensor)`\",\n",
    "         cycle=\"Same as `itertools.cycle`\",\n",
    "         stack=\"Same as `torch.stack`\",\n",
    "         cat=\"Same as `torch.cat`\",\n",
    "         zipped=\"Create new `L` with `zip(*items)`\",\n",
    "         zipwith=\"Create new `L` with `self` zipped with each of `*rest`\",\n",
    "         mapped_zip=\"Combine `zipped` and `starmapped`\",\n",
    "         mapped_zipwith=\"Combine `zipwith` and `starmapped`\",\n",
    "         shuffled=\"Same as `random.shuffle`, but not inplace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create an `L` from an existing iterable (e.g. a list, range, etc) and access or modify it with an int list/tuple index, mask, int, or slice. All `list` methods can also be used with `L`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#12) [11,10,9,j,7,k,5,4,3,2...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = L(range(12))\n",
    "test_eq(t, list(range(12)))\n",
    "test_ne(t, list(range(11)))\n",
    "t.reverse()\n",
    "test_eq(t[0], 11)\n",
    "t[3] = \"h\"\n",
    "test_eq(t[3], \"h\")\n",
    "t[3,5] = (\"j\",\"k\")\n",
    "test_eq(t[3,5], [\"j\",\"k\"])\n",
    "test_eq(t, L(t))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are optimized indexers for arrays, tensors, and DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(9).reshape(3,3)\n",
    "t = L(arr, use_list=None)\n",
    "test_eq(t[1,2], arr[[1,2]])\n",
    "\n",
    "arr = torch.arange(9).view(3,3)\n",
    "t = L(arr, use_list=None)\n",
    "test_eq(t[1,2], arr[[1,2]])\n",
    "\n",
    "df = pd.DataFrame({'a':[1,2,3]})\n",
    "t = L(df, use_list=None)\n",
    "test_eq(t[1,2], L(pd.DataFrame({'a':[2,3]}), use_list=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also modify an `L` with `append`, `+`, and `*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L()\n",
    "test_eq(t, [])\n",
    "t.append(1)\n",
    "test_eq(t, [1])\n",
    "t += [3,2]\n",
    "test_eq(t, [1,3,2])\n",
    "t = t + [4]\n",
    "test_eq(t, [1,3,2,4])\n",
    "t = 5 + t\n",
    "test_eq(t, [5,1,3,2,4])\n",
    "test_eq(L(1,2,3), [1,2,3])\n",
    "test_eq(L(1,2,3), L(1,2,3))\n",
    "t = L(1)*5\n",
    "t = t.mapped(operator.neg)\n",
    "test_eq(t,[-1]*5)\n",
    "test_eq(~L([True,False,False]), L([False,True,True]))\n",
    "t = L(range(4))\n",
    "test_eq(zip(t, L(1).cycle()), zip(range(4),(1,1,1,1)))\n",
    "t = L.range(100)\n",
    "t2 = t.shuffled()\n",
    "test_ne(t,t2)\n",
    "test_eq(L.range(100), t)\n",
    "test_eq(set(t),set(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _f(x,a=0): return x+a\n",
    "t = L(1)*5\n",
    "test_eq(t.mapped(_f), t)\n",
    "test_eq(t.mapped(_f,1), [2]*5)\n",
    "test_eq(t.mapped(_f,a=2), [3]*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `L` can be constructed from anything iterable, although tensors and arrays will not be iterated over on construction, unless you pass `use_list` to the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(L([1,2,3]),[1,2,3])\n",
    "test_eq(L(L([1,2,3])),[1,2,3])\n",
    "test_ne(L([1,2,3]),[1,2,])\n",
    "test_eq(L('abc'),['abc'])\n",
    "test_eq(L(range(0,3)),[0,1,2])\n",
    "test_eq(L(o for o in range(0,3)),[0,1,2])\n",
    "test_eq(L(tensor(0)),[tensor(0)])\n",
    "test_eq(L([tensor(0),tensor(1)]),[tensor(0),tensor(1)])\n",
    "test_eq(L(tensor([0.,1.1]))[0],tensor([0.,1.1]))\n",
    "test_eq(L(tensor([0.,1.1]), use_list=True), [0.,1.1])  # `use_list=True` to unwrap arrays/tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `match` is not `None` then the created list is same len as `match`, either by:\n",
    "\n",
    "- If `len(items)==1` then `items` is replicated,\n",
    "- Otherwise an error is raised if `match` and `items` are not already the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(L(1,match=[1,2,3]),[1,1,1])\n",
    "test_eq(L([1,2],match=[2,3]),[1,2])\n",
    "test_fail(lambda: L([1,2],match=[1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you create an `L` from an existing `L` then you'll get back the original object (since `L` uses the `NewChkMeta` metaclass)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_is(L(t), t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.__getitem__\" class=\"doc_header\"><code>L.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.__getitem__</code>(**`idx`**)\n",
       "\n",
       "Retrieve `idx` (can be list of indices, or mask, or int) items"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L(range(12))\n",
    "test_eq(t[1,2], [1,2])                # implicit tuple\n",
    "test_eq(t[[1,2]], [1,2])              # list\n",
    "test_eq(t[:3], [0,1,2])               # slice\n",
    "test_eq(t[[False]*11 + [True]], [11]) # mask\n",
    "test_eq(t[tensor(3)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.__setitem__\" class=\"doc_header\"><code>L.__setitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.__setitem__</code>(**`idx`**, **`o`**)\n",
       "\n",
       "Set `idx` (can be list of indices, or mask, or int) items to `o` (which is broadcast if not iterable)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.__setitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[4,6] = 0\n",
    "test_eq(t[4,6], [0,0])\n",
    "t[4,6] = [1,2]\n",
    "test_eq(t[4,6], [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.unique\" class=\"doc_header\"><code>L.unique</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.unique</code>()\n",
       "\n",
       "Unique items, in stable order"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(L(1,2,3,4,4).unique(), [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.val2idx\" class=\"doc_header\"><code>L.val2idx</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.val2idx</code>()\n",
       "\n",
       "Dict from value to index"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.val2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(L(1,2,3).val2idx(), {3:2,1:0,2:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.filtered\" class=\"doc_header\"><code>L.filtered</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.filtered</code>(**`f`**, **\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Create new [`L`](/core.html#L) filtered by predicate `f`, passing `args` and `kwargs` to `f`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t.filtered(lambda o:o<5), [0,1,2,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.mapped\" class=\"doc_header\"><code>L.mapped</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.mapped</code>(**`f`**, **\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Create new [`L`](/core.html#L) with `f` applied to all `items`, passing `args` and `kwargs` to `f`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(L(range(4)).mapped(operator.neg), [0,-1,-2,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.mapped_dict\" class=\"doc_header\"><code>L.mapped_dict</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.mapped_dict</code>(**`f`**, **\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Like `mapped`, but creates a dict from `items` to function results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.mapped_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(L(range(1,5)).mapped_dict(operator.neg), {1:-1, 2:-2, 3:-3, 4:-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.zipped\" class=\"doc_header\"><code>L.zipped</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.zipped</code>(**`cycled`**=*`False`*)\n",
       "\n",
       "Create new [`L`](/core.html#L) with `zip(*items)`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L([[1,2,3],'abc'])\n",
    "test_eq(t.zipped(), [(1, 'a'),(2, 'b'),(3, 'c')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L([[1,2,3,4],'abc'])\n",
    "test_eq(t.zipped(cycled=True ), [(1, 'a'),(2, 'b'),(3, 'c'),(4, 'a')])\n",
    "test_eq(t.zipped(cycled=False), [(1, 'a'),(2, 'b'),(3, 'c')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.mapped_zip\" class=\"doc_header\"><code>L.mapped_zip</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.mapped_zip</code>(**`f`**, **`cycled`**=*`False`*)\n",
       "\n",
       "Combine `zipped` and `starmapped`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.mapped_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L([1,2,3],[2,3,4])\n",
    "test_eq(t.mapped_zip(operator.mul), [2,6,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.zipwith\" class=\"doc_header\"><code>L.zipwith</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.zipwith</code>(**\\*`rest`**, **`cycled`**=*`False`*)\n",
       "\n",
       "Create new [`L`](/core.html#L) with `self` zipped with each of `*rest`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.zipwith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[0],[1],[2,2]]\n",
    "t = L([1,2,3]).zipwith(b)\n",
    "test_eq(t, [(1,[0]), (2,[1]), (3,[2,2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.mapped_zipwith\" class=\"doc_header\"><code>L.mapped_zipwith</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.mapped_zipwith</code>(**`f`**, **\\*`rest`**, **`cycled`**=*`False`*)\n",
       "\n",
       "Combine `zipwith` and `starmapped`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.mapped_zipwith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(L(1,2,3).mapped_zipwith(operator.mul, [2,3,4]), [2,6,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.itemgot\" class=\"doc_header\"><code>L.itemgot</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.itemgot</code>(**`idx`**)\n",
       "\n",
       "Create new [`L`](/core.html#L) with item `idx` of all `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.itemgot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t.itemgot(1), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.attrgot\" class=\"doc_header\"><code>L.attrgot</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.attrgot</code>(**`k`**, **`default`**=*`None`*)\n",
       "\n",
       "Create new [`L`](/core.html#L) with attr `k` of all `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.attrgot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [SimpleNamespace(a=3,b=4),SimpleNamespace(a=1,b=2)]\n",
    "test_eq(L(a).attrgot('b'), [4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.sorted\" class=\"doc_header\"><code>L.sorted</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.sorted</code>(**`key`**=*`None`*, **`reverse`**=*`False`*)\n",
       "\n",
       "New [`L`](/core.html#L) sorted by `key`. If key is str then use `attrgetter`. If key is int then use `itemgetter`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(L(a).sorted('a').attrgot('b'), [2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.range\" class=\"doc_header\"><code>L.range</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.range</code>(**`a`**, **`b`**=*`None`*, **`step`**=*`None`*)\n",
       "\n",
       "Same as builtin `range`, but returns an [`L`](/core.html#L). Can pass a collection for `a`, to use `len(a)`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq_type(L.range([1,1,1]), L(range(3)))\n",
    "test_eq_type(L.range(5,2,2), L(range(5,2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.tensored\" class=\"doc_header\"><code>L.tensored</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.tensored</code>()\n",
       "\n",
       "`mapped(tensor)`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.tensored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are shortcuts for `torch.stack` and `torch.cat` if your `L` contains tensors or something convertible. You can manually convert with `tensored`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L(([1,2],[3,4]))\n",
    "test_eq(t.tensored(), [tensor(1,2),tensor(3,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.stack\" class=\"doc_header\"><code>L.stack</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.stack</code>(**`dim`**=*`0`*)\n",
       "\n",
       "Same as `torch.stack`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t.stack(), tensor([[1,2],[3,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.cat\" class=\"doc_header\"><code>L.cat</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01_core.ipynb#L--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.cat</code>(**`dim`**=*`0`*)\n",
       "\n",
       "Same as `torch.cat`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t.cat(), tensor([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ifnone(a, b):\n",
    "    \"`b` if `a` is None else `a`\"\n",
    "    return b if a is None else a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `b if a is None else a` is such a common pattern, we wrap it in a function. However, be careful, because python will evaluate *both* `a` and `b` when calling `ifnone` (which it doesn't do if using the `if` version directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ifnone(None,1), 1)\n",
    "test_eq(ifnone(2   ,1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds):\n",
    "    \"Dynamically create a class, optionally inheriting from `sup`, containing `fld_names`\"\n",
    "    attrs = {}\n",
    "    for f in fld_names: attrs[f] = None\n",
    "    for f in L(funcs): attrs[f.__name__] = f\n",
    "    for k,v in flds.items(): attrs[k] = v\n",
    "    sup = ifnone(sup, ())\n",
    "    if not isinstance(sup, tuple): sup=(sup,)\n",
    "    \n",
    "    def _init(self, *args, **kwargs):\n",
    "        for i,v in enumerate(args): setattr(self, list(attrs.keys())[i], v)\n",
    "        for k,v in kwargs.items(): setattr(self,k,v)\n",
    "            \n",
    "    def _repr(self):\n",
    "        return '\\n'.join(f'{o}: {getattr(self,o)}' for o in set(dir(self))\n",
    "                         if not o.startswith('_') and not isinstance(getattr(self,o), types.MethodType))\n",
    "    \n",
    "    if not sup: attrs['__repr__'] = _repr\n",
    "    attrs['__init__'] = _init\n",
    "    res = type(nm, sup, attrs)\n",
    "    if doc is not None: res.__doc__ = doc\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_t = get_class('_t', 'a', b=2)\n",
    "t = _t()\n",
    "test_eq(t.a, None)\n",
    "test_eq(t.b, 2)\n",
    "t = _t(1, b=3)\n",
    "test_eq(t.a, 1)\n",
    "test_eq(t.b, 3)\n",
    "t = _t(1, 3)\n",
    "test_eq(t.a, 1)\n",
    "test_eq(t.b, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most often you'll want to call `mk_class`, since it adds the class to your module. See `mk_class` for more details and examples of use (which also apply to `get_class`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mk_class(nm, *fld_names, sup=None, doc=None, funcs=None, mod=None, **flds):\n",
    "    \"Create a class using `get_class` and add to the caller's module\"\n",
    "    if mod is None: mod = inspect.currentframe().f_back.f_locals\n",
    "    res = get_class(nm, *fld_names, sup=sup, doc=doc, funcs=funcs, **flds)\n",
    "    mod[nm] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any `kwargs` will be added as class attributes, and `sup` is an optional (tuple of) base classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_class('_t', a=1, sup=GetAttr)\n",
    "t = _t()\n",
    "test_eq(t.a, 1)\n",
    "assert(isinstance(t,GetAttr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `__init__` is provided that sets attrs for any `kwargs`, and for any `args` (matching by position to fields), along with a `__repr__` which prints all attrs. The docstring is set to `doc`. You can pass `funcs` which will be added as attrs with the function names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__._t at 0x7f13998a95f8>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(self): return 1\n",
    "mk_class('_t', 'a', sup=GetAttr, doc='test doc', funcs=foo)\n",
    "\n",
    "t = _t(3, b=2)\n",
    "test_eq(t.a, 3)\n",
    "test_eq(t.b, 2)\n",
    "test_eq(t.foo(), 1)\n",
    "test_eq(t.__doc__, 'test doc')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def wrap_class(nm, *fld_names, sup=None, doc=None, funcs=None, **flds):\n",
    "    \"Decorator: makes function a method of a new class `nm` passing parameters to `mk_class`\"\n",
    "    def _inner(f):\n",
    "        mk_class(nm, *fld_names, sup=sup, doc=doc, funcs=L(funcs)+f, mod=f.__globals__, **flds)\n",
    "        return f\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_class('_t', a=2)\n",
    "def bar(self,x): return x+1\n",
    "\n",
    "t = _t()\n",
    "test_eq(t.a, 2)\n",
    "test_eq(t.bar(3), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"noop\" class=\"doc_header\"><code>noop</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/local/imports.py#L74\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>noop</code>(**`x`**=*`None`*, **\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Do nothing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noop()\n",
    "test_eq(noop(1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"noops\" class=\"doc_header\"><code>noops</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/local/imports.py#L78\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>noops</code>(**`x`**=*`None`*, **\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Do nothing (method)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(noops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_class('_t', foo=noops)\n",
    "test_eq(_t().foo(1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def set_seed(s):\n",
    "    \"Set random seed for `random`, `torch`, and `numpy` (where available)\"\n",
    "    try: torch.manual_seed(s)\n",
    "    except NameError: pass\n",
    "    try: np.random.seed(s%(2**32-1))\n",
    "    except NameError: pass\n",
    "    random.seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(2*33)\n",
    "a1 = np.random.random()\n",
    "a2 = torch.rand(())\n",
    "a3 = random.random()\n",
    "set_seed(2*33)\n",
    "b1 = np.random.random()\n",
    "b2 = torch.rand(())\n",
    "b3 = random.random()\n",
    "test_eq(a1,b1)\n",
    "test_eq(a2,b2)\n",
    "test_eq(a3,b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def store_attr(self, nms):\n",
    "    \"Store params named in comma-separated `nms` from calling context into attrs in `self`\"\n",
    "    mod = inspect.currentframe().f_back.f_locals\n",
    "    for n in re.split(', *', nms): setattr(self,n,mod[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T:\n",
    "    def __init__(self, a,b,c): store_attr(self, 'a,b, c')\n",
    "\n",
    "t = T(1,c=2,b=3)\n",
    "assert t.a==1 and t.b==3 and t.c==2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclassing `Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _fa_rebuild_tensor (cls, *args, **kwargs): return cls(torch._utils._rebuild_tensor_v2(*args, **kwargs))\n",
    "def _fa_rebuild_qtensor(cls, *args, **kwargs): return cls(torch._utils._rebuild_qtensor  (*args, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorBase(Tensor, metaclass=BypassNewMeta):\n",
    "    def _new_meta(self, *args, **kwargs): return tensor(self)\n",
    "\n",
    "    def __reduce_ex__(self,proto):\n",
    "        torch.utils.hooks.warn_if_has_hooks(self)\n",
    "        args = (type(self), self.storage(), self.storage_offset(), tuple(self.size()), self.stride())\n",
    "        if self.is_quantized: args = args + (self.q_scale(), self.q_zero_point())\n",
    "        f = _fa_rebuild_qtensor if self.is_quantized else  _fa_rebuild_tensor\n",
    "        return (f, args + (self.requires_grad, OrderedDict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _patch_tb():\n",
    "    def get_f(fn):\n",
    "        def _f(self, *args, **kwargs):\n",
    "            cls = self.__class__\n",
    "            res = getattr(super(TensorBase, self), fn)(*args, **kwargs)\n",
    "            return cls(res) if isinstance(res,Tensor) else res\n",
    "        return _f\n",
    "    \n",
    "    t = tensor([1])\n",
    "    skips = '__class__ __deepcopy__ __delattr__ __dir__ __doc__ __getattribute__ __hash__ __init__ \\\n",
    "        __init_subclass__ __new__ __reduce__ __reduce_ex__ __module__ __setstate__'.split()\n",
    "\n",
    "    for fn in dir(t):\n",
    "        if fn in skips: continue\n",
    "        f = getattr(t, fn)\n",
    "        if isinstance(f, (MethodWrapperType, BuiltinFunctionType, BuiltinMethodType, MethodType, FunctionType)):\n",
    "            setattr(TensorBase, fn, get_f(fn))\n",
    "\n",
    "_patch_tb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(TensorBase): pass\n",
    "\n",
    "t = _T(range(5))\n",
    "test_eq_type(t[0], _T(0))\n",
    "test_eq_type(t[:2], _T([0,1]))\n",
    "test_eq_type(t+1, _T(range(1,6)))\n",
    "\n",
    "test_eq(type(pickle.loads(pickle.dumps(t))), _T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tuplify(o, use_list=False, match=None):\n",
    "    \"Make `o` a tuple\"\n",
    "    return tuple(L(o, use_list=use_list, match=match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tuplify(None),())\n",
    "test_eq(tuplify([1,2,3]),(1,2,3))\n",
    "test_eq(tuplify(1,match=[1,2,3]),(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def replicate(item,match):\n",
    "    \"Create tuple of `item` copied `len(match)` times\"\n",
    "    return (item,)*len(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [1,1]\n",
    "test_eq(replicate([1,2], t),([1,2],[1,2]))\n",
    "test_eq(replicate(1, t),(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def uniqueify(x, sort=False, bidir=False, start=None):\n",
    "    \"Return the unique elements in `x`, optionally `sort`-ed, optionally return the reverse correspondance.\"\n",
    "    res = L(x).unique()\n",
    "    if start is not None: res = start+res\n",
    "    if sort: res.sort()\n",
    "    if bidir: return res, res.val2idx()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(set(uniqueify([1,1,0,5,0,3])),{0,1,3,5})\n",
    "test_eq(uniqueify([1,1,0,5,0,3], sort=True),[0,1,3,5])\n",
    "v,o = uniqueify([1,1,0,5,0,3], bidir=True)\n",
    "test_eq(v,[1,0,5,3])\n",
    "test_eq(o,{1:0, 0: 1, 5: 2, 3: 3})\n",
    "v,o = uniqueify([1,1,0,5,0,3], sort=True, bidir=True)\n",
    "test_eq(v,[0,1,3,5])\n",
    "test_eq(o,{0:0, 1: 1, 3: 2, 5: 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def setify(o): return o if isinstance(o,set) else set(L(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_eq(setify(None),set())\n",
    "test_eq(setify('abc'),{'abc'})\n",
    "test_eq(setify([1,2,2]),{1,2})\n",
    "test_eq(setify(range(0,3)),{0,1,2})\n",
    "test_eq(setify({1,2}),{1,2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_listy(x):\n",
    "    \"`isinstance(x, (tuple,list,L))`\"\n",
    "    return isinstance(x, (tuple,list,L,slice,Generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_listy([1])\n",
    "assert is_listy(L([1]))\n",
    "assert is_listy(slice(2))\n",
    "assert not is_listy(torch.tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def range_of(x):\n",
    "    \"All indices of collection `x` (i.e. `list(range(len(x)))`)\"\n",
    "    return list(range(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(range_of([1,1,1,1]), [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def groupby(x, key):\n",
    "    \"Like `itertools.groupby` but doesn't need to be sorted, and isn't lazy\"\n",
    "    res = {}\n",
    "    for o in x: res.setdefault(key(o), []).append(o)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(groupby('aa ab bb'.split(), itemgetter(0)), {'a':['aa','ab'], 'b':['bb']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def merge(*ds):\n",
    "    \"Merge all dictionaries in `ds`\"\n",
    "    return {k:v for d in ds for k,v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(merge(), {})\n",
    "test_eq(merge(dict(a=1,b=2)), dict(a=1,b=2))\n",
    "test_eq(merge(dict(a=1,b=2), dict(b=3,c=4)), dict(a=1, b=3, c=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def shufflish(x, pct=0.04):\n",
    "    \"Randomly relocate items of `x` up to `pct` of `len(x)` from their starting location\"\n",
    "    n = len(x)\n",
    "    return L(x[i] for i in sorted(range_of(x), key=lambda o: o+n*(1+random.random()*pct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(range(100))\n",
    "l2 = array(shufflish(l))\n",
    "test_close(l2[:50 ].mean(), 25, eps=5)\n",
    "test_close(l2[-50:].mean(), 75, eps=5)\n",
    "test_ne(l,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IterLen:\n",
    "    \"Base class to add iteration to anything supporting `len` and `__getitem__`\"\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class ReindexCollection(GetAttr, IterLen):\n",
    "    \"Reindexes collection `coll` with indices `idxs` and optional LRU cache of size `cache`\"\n",
    "    def __init__(self, coll, idxs=None, cache=None):\n",
    "        self.default,self.coll,self.idxs,self.cache = coll,coll,ifnone(idxs,L.range(coll)),cache\n",
    "        def _get(self, i): return self.coll[i]\n",
    "        self._get = types.MethodType(_get,self)\n",
    "        if cache is not None: self._get = functools.lru_cache(maxsize=cache)(self._get)\n",
    "\n",
    "    def __getitem__(self, i): return self._get(self.idxs[i])\n",
    "    def __len__(self): return len(self.coll)\n",
    "    def reindex(self, idxs): self.idxs = idxs\n",
    "    def shuffle(self): random.shuffle(self.idxs)\n",
    "    def cache_clear(self): self._get.cache_clear()\n",
    "        \n",
    "    _docs = dict(reindex=\"Replace `self.idxs` with idxs\",\n",
    "                shuffle=\"Randomly shuffle indices\",\n",
    "                cache_clear=\"Clear LRU cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 50\n",
    "t = ReindexCollection(L.range(sz), cache=2)\n",
    "test_eq(list(t), range(sz))\n",
    "test_eq(t[sz-1], sz-1)\n",
    "test_eq(t._get.cache_info().hits, 1)\n",
    "t.shuffle()\n",
    "test_eq(t._get.cache_info().hits, 1)\n",
    "test_ne(list(t), range(sz))\n",
    "test_eq(set(t), set(range(sz)))\n",
    "t.cache_clear()\n",
    "test_eq(t._get.cache_info().hits, 0)\n",
    "test_eq(t.count(0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _oper(op,a,b=None): return (lambda o:op(o,a)) if b is None else op(a,b)\n",
    "\n",
    "def _mk_op(nm, mod=None):\n",
    "    \"Create an operator using `oper` and add to the caller's module\"\n",
    "    if mod is None: mod = inspect.currentframe().f_back.f_locals\n",
    "    op = getattr(operator,nm)\n",
    "    def _inner(a,b=None): return _oper(op, a,b)\n",
    "    _inner.__name__ = _inner.__qualname__ = nm\n",
    "    _inner.__doc__ = f'Same as `operator.{nm}`, or returns partial if 1 arg'\n",
    "    mod[nm] = _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['lt', 'gt', 'le', 'ge', 'eq', 'ne', 'add', 'sub', 'mul', 'truediv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "for op in 'lt gt le ge eq ne add sub mul truediv'.split(): _mk_op(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are provided matching the behavior of the equivalent versions in `operator`:\n",
    "\n",
    " - *lt gt le ge eq ne add sub mul truediv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt(3,5),gt(3,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, they also have additional functionality: if you only pass one param, they return a partial function that passes that param as the second positional parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt(5)(3),gt(5)(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _InfMeta(type):\n",
    "    @property\n",
    "    def count(self): return itertools.count()\n",
    "    @property\n",
    "    def zeros(self): return itertools.cycle([0])\n",
    "    @property\n",
    "    def ones(self):  return itertools.cycle([1])\n",
    "    @property\n",
    "    def nones(self): return itertools.cycle([None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Inf(metaclass=_InfMeta):\n",
    "    \"Infinite lists\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Inf` defines the following properties:\n",
    "    \n",
    "- `count: itertools.count()`\n",
    "- `zeros: itertools.cycle([0])`\n",
    "- `ones : itertools.cycle([1])`\n",
    "- `nones: itertools.cycle([None])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq([o for i,o in zip(range(5), Inf.count)],\n",
    "        [0, 1, 2, 3, 4])\n",
    "\n",
    "test_eq([o for i,o in zip(range(5), Inf.zeros)],\n",
    "        [0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def true(*args, **kwargs):\n",
    "    \"Predicate: always `True`\"\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stop(e=StopIteration):\n",
    "    \"Raises exception `e` (by default `StopException`) even if in an expression\"\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gen(func, seq, cond=true):\n",
    "    \"Like `(func(o) for o in seq if cond(func(o)))` but handles `StopIteration`\"\n",
    "    return itertools.takewhile(cond, map(func,seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(gen(noop, Inf.count, lt(5)),\n",
    "        range(5))\n",
    "test_eq(gen(operator.neg, Inf.count, gt(-5)),\n",
    "        [0,-1,-2,-3,-4])\n",
    "test_eq(gen(lambda o:o if o<5 else stop(), Inf.count),\n",
    "        range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def chunked(it, cs, drop_last=False):\n",
    "    if not isinstance(it, Iterator): it = iter(it)\n",
    "    while True:\n",
    "        res = list(itertools.islice(it, cs))\n",
    "        if res and (len(res)==cs or not drop_last): yield res\n",
    "        if len(res)<cs: return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L.range(10)\n",
    "test_eq(chunked(t,3),      [[0,1,2], [3,4,5], [6,7,8], [9]])\n",
    "test_eq(chunked(t,3,True), [[0,1,2], [3,4,5], [6,7,8],    ])\n",
    "\n",
    "t = map(lambda o:stop() if o==6 else o, Inf.count)\n",
    "test_eq(chunked(t,3), [[0, 1, 2], [3, 4, 5]])\n",
    "t = map(lambda o:stop() if o==7 else o, Inf.count)\n",
    "test_eq(chunked(t,3), [[0, 1, 2], [3, 4, 5], [6]])\n",
    "\n",
    "t = tensor(range(10))\n",
    "test_eq(chunked(t,3),      [[0,1,2], [3,4,5], [6,7,8], [9]])\n",
    "test_eq(chunked(t,3,True), [[0,1,2], [3,4,5], [6,7,8],    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def retain_type(new, old=None, typ=None):\n",
    "    \"Cast `new` to type of `old` if it's a superclass\"\n",
    "    # e.g. old is TensorImage, new is Tensor - if not subclass then do nothing\n",
    "    if new is None: return new\n",
    "    assert old is not None or typ is not None\n",
    "    if typ is None:\n",
    "        if not isinstance(old, type(new)): return new\n",
    "        typ = old if isinstance(old,type) else type(old)\n",
    "    # Do nothing the new type is already an instance of requested type (i.e. same type)\n",
    "    return typ(new) if typ!=NoneType and not isinstance(new, typ) else new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(tuple): pass\n",
    "a = _T((1,2))\n",
    "b = tuple((1,2))\n",
    "test_eq_type(retain_type(b, typ=_T), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def retain_types(new, old=None, typs=None):\n",
    "    \"Cast each item of `new` to type of matching item in `old` if it's a superclass\"\n",
    "    if not is_listy(new): return retain_type(new, old, typs)\n",
    "    return tuple(L(new, old, typs).mapped_zip(retain_type, cycled=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T(tuple): pass\n",
    "\n",
    "t1,t2 = retain_types((tensor(1),(tensor(1),)), (TensorBase(2),T((2,))))\n",
    "test_eq_type(t1, TensorBase(1))\n",
    "test_eq_type(t2, T((tensor(1),)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def concat(*ls):\n",
    "    \"Concatenate tensors, arrays, lists, or tuples\"\n",
    "    if not len(ls): return []\n",
    "    it = ls[0]\n",
    "    if isinstance(it,torch.Tensor): res = torch.cat(ls) \n",
    "    elif isinstance(it,ndarray): res = np.concatenate(ls)\n",
    "    else:\n",
    "        res = [o for x in ls for o in L(x)]\n",
    "        if isinstance(it,(tuple,list)): res = type(it)(res)\n",
    "        else: res = L(res)\n",
    "    return retain_type(res, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = [1],[1,2],[1,1,2]\n",
    "test_eq(concat(a,b), c)\n",
    "test_eq_type(concat(tuple (a),tuple (b)), tuple (c))\n",
    "test_eq_type(concat(array (a),array (b)), array (c))\n",
    "test_eq_type(concat(tensor(a),tensor(b)), tensor(c))\n",
    "test_eq_type(concat(TensorBase(a),TensorBase(b)), TensorBase(c))\n",
    "test_eq_type(concat([1,1],1), [1,1,1])\n",
    "test_eq_type(concat(1,1,1), L(1,1,1))\n",
    "test_eq_type(concat(L(1,2),1), L(1,2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunks -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Chunks:\n",
    "    \"Slice and int indexing into a list of lists\"\n",
    "    def __init__(self, chunks, lens=None):\n",
    "        self.chunks = chunks\n",
    "        self.lens = L(map(len,self.chunks) if lens is None else lens)\n",
    "        self.cumlens = np.cumsum(0+self.lens)\n",
    "        self.totlen = self.cumlens[-1]\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        if isinstance(i,slice): return self.getslice(i)\n",
    "        di,idx = self.doc_idx(i)\n",
    "        return self.chunks[di][idx]\n",
    "\n",
    "    def getslice(self, i):\n",
    "        st_d,st_i = self.doc_idx(ifnone(i.start,0))\n",
    "        en_d,en_i = self.doc_idx(ifnone(i.stop,self.totlen+1))\n",
    "        res = [self.chunks[st_d][st_i:(en_i if st_d==en_d else sys.maxsize)]]\n",
    "        for b in range(st_d+1,en_d): res.append(self.chunks[b])\n",
    "        if st_d!=en_d and en_d<len(self.chunks): res.append(self.chunks[en_d][:en_i])\n",
    "        return concat(*res)\n",
    "    \n",
    "    def doc_idx(self, i):\n",
    "        if i<0: i=self.totlen+i # count from end\n",
    "        docidx = np.searchsorted(self.cumlens, i+1)-1\n",
    "        cl = self.cumlens[docidx]\n",
    "        return docidx,i-cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = L(list(string.ascii_lowercase[a:b]) for a,b in ((0,3),(3,7),(7,8),(8,16),(16,24),(24,26)))\n",
    "\n",
    "b = Chunks(docs)\n",
    "test_eq([b[ o] for o in range(0,5)], ['a','b','c','d','e'])\n",
    "test_eq([b[-o] for o in range(1,6)], ['z','y','x','w','v'])\n",
    "test_eq(b[6:13], 'g,h,i,j,k,l,m'.split(','))\n",
    "test_eq(b[20:77], 'u,v,w,x,y,z'.split(','))\n",
    "test_eq(b[:5], 'a,b,c,d,e'.split(','))\n",
    "test_eq(b[:2], 'a,b'.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(26)\n",
    "docs = L(t[a:b] for a,b in ((0,3),(3,7),(7,8),(8,16),(16,24),(24,26)))\n",
    "b = Chunks(docs)\n",
    "test_eq([b[ o] for o in range(0,5)], range(0,5))\n",
    "test_eq([b[-o] for o in range(1,6)], [25,24,23,22,21])\n",
    "test_eq(b[6:13], torch.arange(6,13))\n",
    "test_eq(b[20:77], torch.arange(20,26))\n",
    "test_eq(b[:5], torch.arange(5))\n",
    "test_eq(b[:2], torch.arange(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = L(TensorBase(t[a:b]) for a,b in ((0,3),(3,7),(7,8),(8,16),(16,24),(24,26)))\n",
    "b = Chunks(docs)\n",
    "test_eq_type(b[:2], TensorBase(range(2)))\n",
    "test_eq_type(b[:5], TensorBase(range(5)))\n",
    "test_eq_type(b[9:13], TensorBase(range(9,13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.TensorBase"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b[9:13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions on functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def trace(f):\n",
    "    \"Add `set_trace` to an existing function `f`\"\n",
    "    def _inner(*args,**kwargs):\n",
    "        set_trace()\n",
    "        return f(*args,**kwargs)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def compose(*funcs, order=None):\n",
    "    \"Create a function that composes all functions in `funcs`, passing along remaining `*args` and `**kwargs` to all\"\n",
    "    funcs = L(funcs)\n",
    "    if order is not None: funcs = funcs.sorted(order)\n",
    "    def _inner(x, *args, **kwargs):\n",
    "        for f in L(funcs): x = f(x, *args, **kwargs)\n",
    "        return x\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = lambda o,p=0: (o*2)+p\n",
    "f2 = lambda o,p=1: (o+1)/p\n",
    "test_eq(f2(f1(3)), compose(f1,f2)(3))\n",
    "test_eq(f2(f1(3,p=3),p=3), compose(f1,f2)(3,p=3))\n",
    "test_eq(f2(f1(3,  3),  3), compose(f1,f2)(3,  3))\n",
    "\n",
    "f1.order = 1\n",
    "test_eq(f1(f2(3)), compose(f1,f2, order=\"order\")(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def maps(*args, retain=noop):\n",
    "    \"Like `map`, except funcs are composed first\"\n",
    "    f = compose(*args[:-1])\n",
    "    def _f(b): return retain(f(b), b)\n",
    "    return map(_f, args[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(maps([1]), [1])\n",
    "test_eq(maps(operator.neg, [1,2]), [-1,-2])\n",
    "test_eq(maps(operator.neg, operator.neg, [1,2]), [1,2])\n",
    "\n",
    "test_eq_type(list(maps(operator.neg, [TensorBase(1), 2], retain=retain_type)), \n",
    "             [TensorBase(-1), -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def partialler(f, *args, order=None, **kwargs):\n",
    "    \"Like `functools.partial` but also copies over docstring\"\n",
    "    fnew = partial(f,*args,**kwargs)\n",
    "    fnew.__doc__ = f.__doc__\n",
    "    if order is not None: fnew.order=order\n",
    "    elif hasattr(f,'order'): fnew.order=f.order\n",
    "    return fnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _f(x,a=1):\n",
    "    \"test func\"\n",
    "    return x+a\n",
    "_f.order=1\n",
    "\n",
    "f = partialler(_f, a=2)\n",
    "test_eq(f.order, 1)\n",
    "f = partialler(_f, a=2, order=3)\n",
    "test_eq(f.__doc__, \"test func\")\n",
    "test_eq(f.order, 3)\n",
    "test_eq(f(3), _f(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def instantiate(t):\n",
    "    \"Instantiate `t` if it's a type, otherwise do nothing\"\n",
    "    return t() if isinstance(t, type) else t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq_type(instantiate(int), 0)\n",
    "test_eq_type(instantiate(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "mk_class('_Arg', 'i')\n",
    "_0,_1,_2,_3,_4 = _Arg(0),_Arg(1),_Arg(2),_Arg(3),_Arg(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['_0', '_1', '_2', '_3', '_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class bind:\n",
    "    \"Same as `partial`, except you can use `_0` `_1` etc param placeholders\"\n",
    "    def __init__(self, fn, *pargs, **pkwargs):\n",
    "        store_attr(self, 'fn,pargs,pkwargs')\n",
    "        self.maxi = max((x.i for x in pargs if isinstance(x, _Arg)), default=-1)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        fargs = L(args[x.i] if isinstance(x, _Arg) else x for x in self.pargs) + args[self.maxi+1:]\n",
    "        return self.fn(*fargs, **{**self.pkwargs, **kwargs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfn(a,b,c,d=1,e=2): return(a,b,c,d,e)\n",
    "test_eq(bind(myfn, _1, 17, _0, e=3)(19,14), (14,17,19,1,3))\n",
    "test_eq(bind(myfn, 17, _0, e=3)(19,14), (17,19,14,1,3))\n",
    "test_eq(bind(myfn, 17, e=3)(19,14), (17,19,14,1,3))\n",
    "test_eq(bind(myfn)(17,19,14), (17,19,14,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File and network functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#NB: Please don't move this to a different line or module, since it's used in testing `get_source_link`\n",
    "@patch\n",
    "def ls(self:Path, file_type=None, file_exts=None):\n",
    "    \"Contents of path as a list\"\n",
    "    extns=L(file_exts)\n",
    "    if file_type: extns += L(k for k,v in mimetypes.types_map.items() if v.startswith(file_type+'/'))\n",
    "    return L(self.iterdir()).filtered(lambda x: len(extns)==0 or x.suffix in extns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an `ls()` method to `pathlib.Path` which is simply defined as `list(Path.iterdir())`, mainly for convenience in REPL environments such as notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('18_callback_fp16.ipynb')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path()\n",
    "t = path.ls()\n",
    "assert len(t)>0\n",
    "t[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass an optional `file_type` MIME prefix and/or a list of file extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('train_wt2.py'), PosixPath('18_callback_fp16.ipynb'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_files=path.ls(file_type='text')\n",
    "assert len(txt_files) > 0 and txt_files[0].suffix=='.py'\n",
    "ipy_files=path.ls(file_exts=['.ipynb'])\n",
    "assert len(ipy_files) > 0 and ipy_files[0].suffix=='.ipynb'\n",
    "txt_files[0],ipy_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pkl = pickle.dumps(path)\n",
    "p2 =pickle.loads(pkl)\n",
    "test_eq(path.ls()[0], p2.ls()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bunzip(fn):\n",
    "    \"bunzip `fn`, raising exception if output already exists\"\n",
    "    fn = Path(fn)\n",
    "    assert fn.exists(), f\"{fn} doesn't exist\"\n",
    "    out_fn = fn.with_suffix('')\n",
    "    assert not out_fn.exists(), f\"{out_fn} already exists\"\n",
    "    with bz2.BZ2File(fn, 'rb') as src, out_fn.open('wb') as dst:\n",
    "        for d in iter(lambda: src.read(1024*1024), b''): dst.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Path('files/test.txt')\n",
    "if f.exists(): f.unlink()\n",
    "bunzip('files/test.txt.bz2')\n",
    "t = f.open().readlines()\n",
    "test_eq(len(t),1)\n",
    "test_eq(t[0], 'test\\n')\n",
    "f.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply(func, x, *args, **kwargs):\n",
    "    \"Apply `func` recursively to `x`, passing on args\"\n",
    "    if is_listy(x): return type(x)([apply(func, o, *args, **kwargs) for o in x])\n",
    "    if isinstance(x,dict):  return {k: apply(func, v, *args, **kwargs) for k,v in x.items()}\n",
    "    res = func(x, *args, **kwargs)\n",
    "    return res if x is None else retain_type(res, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_detach(b, cpu=True):\n",
    "    \"Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`.\"\n",
    "    def _inner(x, cpu=True):\n",
    "        if not isinstance(x,Tensor): return x\n",
    "        x = x.detach()\n",
    "        return x.cpu() if cpu else x\n",
    "    return apply(_inner, b, cpu=cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_half(b):\n",
    "    \"Recursively map lists of tensors in `b ` to FP16.\"\n",
    "    return apply(lambda x: x.half() if torch.is_floating_point(x) else x, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_float(b):\n",
    "    \"Recursively map lists of int tensors in `b ` to float.\"\n",
    "    return apply(lambda x: x.float() if torch.is_floating_point(x) else x, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# None: True if available; True: error if not availabe; False: use CPU\n",
    "defaults.use_cuda = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def default_device(use_cuda=-1):\n",
    "    \"Return or set default device; `use_cuda`: None - CUDA if available; True - error if not availabe; False - CPU\"\n",
    "    if use_cuda != -1: defaults.use_cuda=use_cuda\n",
    "    use = defaults.use_cuda or (torch.cuda.is_available() and defaults.use_cuda is None)\n",
    "    assert torch.cuda.is_available() or not use\n",
    "    return torch.device(torch.cuda.current_device()) if use else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuda\n",
    "_td = torch.device(torch.cuda.current_device())\n",
    "test_eq(default_device(None), _td)\n",
    "test_eq(default_device(True), _td)\n",
    "test_eq(default_device(False), torch.device('cpu'))\n",
    "default_device(None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_device(b, device=None):\n",
    "    \"Recursively put `b` on `device`.\"\n",
    "    if device is None: device=default_device()\n",
    "    def _inner(o): return o.to(device, non_blocking=True) if isinstance(o,Tensor) else o\n",
    "    return apply(_inner, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = to_device((3,(tensor(3),tensor(2))))\n",
    "t1,(t2,t3) = t\n",
    "test_eq_type(t,(3,(tensor(3).cuda(),tensor(2).cuda())))\n",
    "test_eq(t2.type(), \"torch.cuda.LongTensor\")\n",
    "test_eq(t3.type(), \"torch.cuda.LongTensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_cpu(b):\n",
    "    \"Recursively map lists of tensors in `b ` to the cpu.\"\n",
    "    return to_device(b,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = to_cpu(t3)\n",
    "test_eq(t3.type(), \"torch.LongTensor\")\n",
    "test_eq(t3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    \"Convert a tensor to a numpy array.\"\n",
    "    return x.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = to_np(t3)\n",
    "test_eq(type(t3), np.ndarray)\n",
    "test_eq(t3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def item_find(x, idx=0):\n",
    "    \"Recursively takes the `idx`-th element of `x`\"\n",
    "    if is_listy(x): return item_find(x[idx])\n",
    "    if isinstance(x,dict):  \n",
    "        key = list(x.keys())[idx] if isinstance(idx, int) else idx\n",
    "        return item_find(x[key])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_device(b):\n",
    "    \"Recursively search the device of `b`.\"\n",
    "    return item_find(b).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = default_device()\n",
    "test_eq(find_device(t2), dev)\n",
    "test_eq(find_device([t2,t2]), dev)\n",
    "test_eq(find_device({'a':t2,'b':t2}), dev)\n",
    "test_eq(find_device({'a':[[t2],[t2]],'b':t2}), dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_bs(b):\n",
    "    \"Recursively search the batch size of `b`.\"\n",
    "    return item_find(b).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4,5)\n",
    "test_eq(find_bs(x), 4)\n",
    "test_eq(find_bs([x, x]), 4)\n",
    "test_eq(find_bs({'a':x,'b':x}), 4)\n",
    "test_eq(find_bs({'a':[[x],[x]],'b':x}), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_func(f):\n",
    "    \"Convert a function taking and returning numpy arrays to one taking and returning tensors\"\n",
    "    def _inner(*args, **kwargs):\n",
    "        nargs = [to_np(arg) if isinstance(arg,Tensor) else arg for arg in args]\n",
    "        return tensor(f(*nargs, **kwargs))\n",
    "    functools.update_wrapper(_inner, f)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This decorator is particularly useful for using numpy functions as fastai metrics, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "@np_func\n",
    "def f1(inp,targ): return f1_score(targ, inp)\n",
    "\n",
    "a1,a2 = array([0,1,1]),array([1,0,1])\n",
    "t = f1(tensor(a1),tensor(a2))\n",
    "test_eq(f1_score(a1,a2), t)\n",
    "assert isinstance(t,Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Module(nn.Module, metaclass=PrePostInitMeta):\n",
    "    \"Same as `nn.Module`, but no need for subclasses to call `super().__init__`\"\n",
    "    def __pre_init__(self): super().__init__()\n",
    "    def __init__(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"Module\" class=\"doc_header\"><code>class</code> <code>Module</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/11_layers.ipynb#Basic-manipulations-and-resize\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>Module</code>() :: [`Module`](/layers.html#Module)\n",
       "\n",
       "Same as `nn.Module`, but no need for subclasses to call `super().__init__`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Module, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0893], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _T(Module):\n",
    "    def __init__(self): self.f = nn.Linear(1,1)\n",
    "    def forward(self,x): return self.f(x)\n",
    "\n",
    "t = _T()\n",
    "t(tensor([1.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting objects from before/after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms and callbacks will have run_after/run_before attributes, this function will sort them to respect those requirements (if it's possible). Also, sometimes we want a tranform/callback to be run at the end, but still be able to use run_after/run_before behaviors. For those, the function checks for a toward_end attribute (that needs to be True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _is_instance(f, gs):\n",
    "    tst = [g if type(g) in [type, 'function'] else g.__class__ for g in gs]\n",
    "    for g in tst:\n",
    "        if isinstance(f, g) or f==g: return True\n",
    "    return False\n",
    "\n",
    "def _is_first(f, gs):\n",
    "    for o in L(getattr(f, 'run_after', None)): \n",
    "        if _is_instance(o, gs): return False\n",
    "    for g in gs:\n",
    "        if _is_instance(f, L(getattr(g, 'run_before', None))): return False\n",
    "    return True\n",
    "\n",
    "def sort_by_run(fs):\n",
    "    end = L(getattr(f, 'toward_end', False) for f in fs)\n",
    "    inp,res = L(fs)[~end] + L(fs)[end], []\n",
    "    while len(inp) > 0:\n",
    "        for i,o in enumerate(inp):\n",
    "            if _is_first(o, inp): \n",
    "                res.append(inp.pop(i))\n",
    "                break\n",
    "        else: raise Exception(\"Impossible to sort\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tst(): pass    \n",
    "class Tst1():\n",
    "    run_before=[Tst]\n",
    "class Tst2():\n",
    "    run_before=Tst\n",
    "    run_after=Tst1\n",
    "    \n",
    "tsts = [Tst(), Tst1(), Tst2()]\n",
    "test_eq(sort_by_run(tsts), [tsts[1], tsts[2], tsts[0]])\n",
    "\n",
    "Tst2.run_before,Tst2.run_after = Tst1,Tst\n",
    "test_fail(lambda: sort_by_run([Tst(), Tst1(), Tst2()]))\n",
    "\n",
    "def tst1(x): return x\n",
    "tst1.run_before = Tst\n",
    "test_eq(sort_by_run([tsts[0], tst1]), [tst1, tsts[0]])\n",
    "    \n",
    "class Tst1():\n",
    "    toward_end=True\n",
    "class Tst2():\n",
    "    toward_end=True\n",
    "    run_before=Tst1\n",
    "tsts = [Tst(), Tst1(), Tst2()]\n",
    "test_eq(sort_by_run(tsts), [tsts[0], tsts[2], tsts[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def round_multiple(x, mult, round_down=False):\n",
    "    \"Round `x` to nearest multiple of `mult`\"\n",
    "    def _f(x_): return (int if round_down else round)(x_/mult)*mult\n",
    "    res = L(x).mapped(_f)\n",
    "    return res if is_listy(x) else res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(round_multiple(63,32), 64)\n",
    "test_eq(round_multiple(50,32), 64)\n",
    "test_eq(round_multiple(40,32), 32)\n",
    "test_eq(round_multiple( 0,32),  0)\n",
    "test_eq(round_multiple(63,32, round_down=True), 32)\n",
    "test_eq(round_multiple((63,40),32), (64,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def num_cpus():\n",
    "    \"Get number of cpus\"\n",
    "    try:                   return len(os.sched_getaffinity(0))\n",
    "    except AttributeError: return os.cpu_count()\n",
    "    \n",
    "defaults.cpus = num_cpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_props(f, n=2):\n",
    "    \"Create properties passing each of `range(n)` to f\"\n",
    "    return (property(partial(f,i)) for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(): a,b = add_props(lambda i,x:i*2)\n",
    "\n",
    "t = _T()\n",
    "test_eq(t.a,0)\n",
    "test_eq(t.b,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick way to generate, for instance, *train* and *valid* versions of a property. See `DataBunch` definition for an example of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_cross_image(bw=True):\n",
    "    \"Create a tensor containing a cross image, either `bw` (True) or color\"\n",
    "    if bw:\n",
    "        im = torch.zeros(5,5)\n",
    "        im[2,:] = 1.\n",
    "        im[:,2] = 1.\n",
    "    else:\n",
    "        im = torch.zeros(3,5,5)\n",
    "        im[0,2,:] = 1.\n",
    "        im[1,:,2] = 1.\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(make_cross_image(), cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(make_cross_image(False).permute(1,2,0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_title(o, ax=None, ctx=None, label=None, **kwargs):\n",
    "    \"Set title of `ax` to `o`, or print `o` if `ax` is `None`\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: print(o)\n",
    "    elif hasattr(ax, 'set_title'): ax.set_title(o)\n",
    "    elif isinstance(ax, pd.Series):\n",
    "        while label in ax: label += '_'\n",
    "        ax = ax.append(pd.Series({label: o}))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: show_title(\"title\"), \"title\")\n",
    "# ensure that col names are unique when showing to a pandas series\n",
    "assert show_title(\"title\", ctx=pd.Series(dict(a=1)), label='a').equals(pd.Series(dict(a=1,a_='title')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_image(im, ax=None, figsize=None, title=None, ctx=None, **kwargs):\n",
    "    \"Show a PIL or PyTorch image on `ax`.\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: _,ax = plt.subplots(figsize=figsize)\n",
    "    # Handle pytorch axis order\n",
    "    if isinstance(im,Tensor):\n",
    "        im = to_cpu(im)\n",
    "        if im.shape[0]<5: im=im.permute(1,2,0)\n",
    "    elif not isinstance(im,np.ndarray): im=array(im)\n",
    "    # Handle 1-channel images\n",
    "    if im.shape[-1]==1: im=im[...,0]\n",
    "    ax.imshow(im, **kwargs)\n",
    "    if title is not None: ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_image` can show b&w images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAABZUlEQVR4nO3dSQrDMBAAwSjk/19WXpDxJQtKV10NxqjRQWBGa+99o+H+6w/ge8QOETtE7BCxQ8QOeVw8P+pcttZ6+zsPPJq+XAQ7O0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxtmln5gFeprT1mCatWpnh4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CHjD4enXRTusvSZnR0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIeufZnMys7NDxA4RO0TsELFDxA55Ao0DE/UW4fj8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = make_cross_image()\n",
    "ax = show_image(im, cmap=\"Greys\", figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and color images with standard `c*h*w` dim order..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAABYUlEQVR4nO3dQQrCMBBAUSPe/8rjCYwbUyn/vW2hDHxmUSjJmpkHDc9/D8B1xA4RO0TsELFDxA557R6ute71XXZi2nXgnQfNzMeJbXaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih2zPLr3XwaV8Y7NDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TskP1l6VdNwc/sfhK12SFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdsmZciV5hs0PEDhE7ROwQsUPEDnkD1tcN9ECq4WMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im2 = make_cross_image(False)\n",
    "ax = show_image(im2, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and color images with `h*w*c` dim order..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAABYUlEQVR4nO3dQQrCMBBAUSPe/8rjCYwbUyn/vW2hDHxmUSjJmpkHDc9/D8B1xA4RO0TsELFDxA557R6ute71XXZi2nXgnQfNzMeJbXaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih2zPLr3XwaV8Y7NDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TskP1l6VdNwc/sfhK12SFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdsmZciV5hs0PEDhE7ROwQsUPEDnkD1tcN9ECq4WMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im3 = im2.permute(1,2,0)\n",
    "ax = show_image(im3, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f13902e5e48>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAACLCAYAAABBVeZmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAADqUlEQVR4nO3dO2sUYRiG4fuNiuksVMQIRmwEC7ERVNKIlkps0hi0srTwUCgYg1oIYhMC+gtELQQVFCFtkIDmByioKGoUT6iJB0jiazFThBBXlCSbz+e5YIqdmV129p7DtyTMRmZiGlqa/QZs/ji2EMcW4thCHFuIYwtxbCFFx46IfRExHBFjEfE6Iu5GREez39dCVWzsiDgK9AHngFXAWuAS0DnDuovn990tUJlZ3AQsA8aArt8sPw1cBy4DX4CDwFKqnWOknvqApfX6K4DbwCfgIzAItNTLjgOvgFHgEbCz2dv/r1Ope/w2oBW40WCdTqALOEAV+iSwFdgMJHAL6AFOAceAl8DK+rlbgYyIDcAhYEtmjkTEOmDRLG/LvCn1NL4ceJ+ZEw3WGcrMm5n5MzO/A93A2cx8m5nvgDPA/nrdcWA10J6Z45k5mNVhPUm1o2yMiCWZ+Swzn8zdZs2tUmN/AFb84Vr8YtrjNuD5lMfP63kAF4DHwEBEPI2IEwCZ+Rg4THVZeBsR1yKijUKVGnsI+AHsbbDO9D/njQDtUx6vreeRmaOZeSwz1wN7gKMRsbNediUzO+rnJnB+djZh/hV5zc7MzxHRC1yMiAlggOpUvAvYAXyb4WlXgZ6IeEAVrZdqAEdE7AYeAk+oBnSTwGR9zV4D3KPaub5T7gFS5mh8yqi7GxgGvgJvgDvAdqrT7uVp67YC/cDreuoHWutlR4Bn9eu8BE7V8zcB96lG4h+pRuxtzd7uf52i3igTUO4pyf6aYwtxbCGOLcSxhfzpe3ZRQ/WImPXXLPDbym8/BB/ZQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLaXjv0rm4F2hpSvsMGt1r1Ue2EMcW4thCHFuIYwtxbCGOLcSxhTi2EMcW4thCHFuIYwtxbCGOLcSxhTi2EMcW4thCHFtIw384LO2Hwv1j6Y35yBbi2EIcW4hjC3FsIY4txLGFOLYQxxbi2EIcW4hjC3FsIY4txLGFOLYQxxbi2EIcW4hjC3FsIY4txLGFOLYQxxbi2EIcW4hjC3FsIY4txLGFOLYQxxbi2EIcW4hjC3FsIY4txLGFOLYQxxbi2EIcW0j8T/fmtMZ8ZAtxbCGOLcSxhTi2EMcW8gsg1f8mDj+bqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_image(im, cmap=\"Greys\", figsize=(2,2))\n",
    "show_title(\"Cross\", ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_titled_image(o, **kwargs):\n",
    "    \"Call `show_image` destructuring `o` to `(img,title)`\"\n",
    "    show_image(o[0], title=str(o[1]), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_image_batch(b, show=show_titled_image, items=9, cols=3, figsize=None, **kwargs):\n",
    "    \"Display batch `b` in a grid of size `items` with `cols` width\"\n",
    "    rows = (items+cols-1) // cols\n",
    "    if figsize is None: figsize = (cols*3, rows*3)\n",
    "    fig,axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "    for *o,ax in zip(*to_cpu(b), axs.flatten()): show(o, ax=ax, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image_batch(([im,im2,im3],['bw','chw','hwc']), items=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_dataloader.ipynb.\n",
      "Converted 01a_script.ipynb.\n",
      "Converted 02_data_transforms.ipynb.\n",
      "Converted 03_data_pipeline.ipynb.\n",
      "Converted 04_data_external.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_source.ipynb.\n",
      "Converted 07_vision_core.ipynb.\n",
      "Converted 08_pets_tutorial.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 11_layers.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_metrics.ipynb.\n",
      "Converted 21_tutorial_imagenette.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_test_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 50_data_block.ipynb.\n",
      "Converted 60_vision_models_xresnet.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai_dev",
   "language": "python",
   "name": "fastai_dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
