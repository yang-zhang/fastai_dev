{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_006b import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikitext 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset [here](https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip) and unzip it so it's in the folder wikitext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://research.metamind.io/wikitext/wikitext-2-v1.zip to data/wikitext-2-v1.zip\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://research.metamind.io/wikitext/wikitext-2-v1.zip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/wikitext-2-v1.zip\n",
      "   creating: data/wikitext-2/\n",
      "  inflating: data/wikitext-2/wiki.test.tokens  \n",
      "  inflating: data/wikitext-2/wiki.valid.tokens  \n",
      "  inflating: data/wikitext-2/wiki.train.tokens  \n"
     ]
    }
   ],
   "source": [
    "!unzip data/wikitext-2-v1.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS = '<eos>'\n",
    "PATH=Path('data/wikitext-2/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small helper function to read the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    tokens = []\n",
    "    with open(PATH/filename, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            tokens.append(line.split() + [EOS])\n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = read_file('wiki.train.tokens')\n",
    "valid_tok = read_file('wiki.valid.tokens')\n",
    "test_tok = read_file('wiki.test.tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['<eos>']),\n",
       "       list(['=', 'Valkyria', 'Chronicles', 'III', '=', '<eos>']),\n",
       "       list(['<eos>']),\n",
       "       list(['Senjō', 'no', 'Valkyria', '3', ':', '<unk>', 'Chronicles', '(', 'Japanese', ':', '戦場のヴァルキュリア3', ',', 'lit', '.', 'Valkyria', 'of', 'the', 'Battlefield', '3', ')', ',', 'commonly', 'referred', 'to', 'as', 'Valkyria', 'Chronicles', 'III', 'outside', 'Japan', ',', 'is', 'a', 'tactical', 'role', '@-@', 'playing', 'video', 'game', 'developed', 'by', 'Sega', 'and', 'Media.Vision', 'for', 'the', 'PlayStation', 'Portable', '.', 'Released', 'in', 'January', '2011', 'in', 'Japan', ',', 'it', 'is', 'the', 'third', 'game', 'in', 'the', 'Valkyria', 'series', '.', '<unk>', 'the', 'same', 'fusion', 'of', 'tactical', 'and', 'real', '@-@', 'time', 'gameplay', 'as', 'its', 'predecessors', ',', 'the', 'story', 'runs', 'parallel', 'to', 'the', 'first', 'game', 'and', 'follows', 'the', '\"', 'Nameless', '\"', ',', 'a', 'penal', 'military', 'unit', 'serving', 'the', 'nation', 'of', 'Gallia', 'during', 'the', 'Second', 'Europan', 'War', 'who', 'perform', 'secret', 'black', 'operations', 'and', 'are', 'pitted', 'against', 'the', 'Imperial', 'unit', '\"', '<unk>', 'Raven', '\"', '.', '<eos>']),\n",
       "       list(['The', 'game', 'began', 'development', 'in', '2010', ',', 'carrying', 'over', 'a', 'large', 'portion', 'of', 'the', 'work', 'done', 'on', 'Valkyria', 'Chronicles', 'II', '.', 'While', 'it', 'retained', 'the', 'standard', 'features', 'of', 'the', 'series', ',', 'it', 'also', 'underwent', 'multiple', 'adjustments', ',', 'such', 'as', 'making', 'the', 'game', 'more', '<unk>', 'for', 'series', 'newcomers', '.', 'Character', 'designer', '<unk>', 'Honjou', 'and', 'composer', 'Hitoshi', 'Sakimoto', 'both', 'returned', 'from', 'previous', 'entries', ',', 'along', 'with', 'Valkyria', 'Chronicles', 'II', 'director', 'Takeshi', 'Ozawa', '.', 'A', 'large', 'team', 'of', 'writers', 'handled', 'the', 'script', '.', 'The', 'game', \"'s\", 'opening', 'theme', 'was', 'sung', 'by', 'May', \"'n\", '.', '<eos>'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tok[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36718, 3760, 4358)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tok), len(valid_tok), len(test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_tok[4][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 113161),\n",
       " (',', 99913),\n",
       " ('.', 73388),\n",
       " ('of', 56889),\n",
       " ('<unk>', 54625),\n",
       " ('and', 50603),\n",
       " ('in', 39453),\n",
       " ('to', 39190),\n",
       " ('<eos>', 36718),\n",
       " ('a', 34237)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter(word for sent in train_tok for word in sent)\n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give an id to each token and add the pad token (just in case we need it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in cnt.most_common()]\n",
    "itos.insert(0,'<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33279"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(itos); vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the mapping from token to id then numericalizing our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda : 5, {w:i for i,w in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.array([([stoi[w] for w in s]) for s in train_tok])\n",
    "valid_ids = np.array([([stoi[w] for w in s]) for s in valid_tok])\n",
    "test_ids = np.array([([stoi[w] for w in s]) for s in test_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3760,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([9]), list([11, 10854, 33171, 11, 9]), list([9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ids[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LanguageModelLoader():\n",
    "    \"Creates a dataloader with bptt slightly changing.\"\n",
    "    \n",
    "    def __init__(self, nums:np.ndarray, bs:int=64, bptt:int=70, backwards:bool=False):\n",
    "        self.bs,self.bptt,self.backwards = bs,bptt,backwards\n",
    "        self.data = self.batchify(nums)\n",
    "        self.first,self.i,self.iter = True,0,0\n",
    "        self.n = len(self.data)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i,self.iter = 0,0\n",
    "        while self.i < self.n-1 and self.iter<len(self):\n",
    "            if self.first and self.i == 0: self.first,seq_len = False,self.bptt + 25\n",
    "            else:\n",
    "                bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n",
    "                seq_len = max(5, int(np.random.normal(bptt, 5)))\n",
    "            res = self.get_batch(self.i, seq_len)\n",
    "            self.i += seq_len\n",
    "            self.iter += 1\n",
    "            yield res\n",
    "\n",
    "    def __len__(self) -> int: return (self.n-1) // self.bptt\n",
    "\n",
    "    def batchify(self, data:np.ndarray) -> LongTensor:\n",
    "        \"Splits the data in batches.\"\n",
    "        nb = data.shape[0] // self.bs\n",
    "        # breakpoint()\n",
    "        # train\n",
    "        # data.shape (2088628,)\n",
    "        # np.array(data[:nb*self.bs]).shape (2088620,)\n",
    "        # self.bs 20\n",
    "        # np.array(data[:nb*self.bs]).reshape(self.bs, -1).shape (20, 104431)\n",
    "        # np.array(data[:nb*self.bs]).reshape(self.bs, -1).T.shape (104431, 20)\n",
    "        data = np.array(data[:nb*self.bs]).reshape(self.bs, -1).T\n",
    "    \n",
    "        if self.backwards: data=data[::-1]\n",
    "        return LongTensor(data)\n",
    "\n",
    "    def get_batch(self, i:int, seq_len:int) -> LongTensor:\n",
    "        \"Gets a batch of length `seq_len`\"\n",
    "        seq_len = min(seq_len, len(self.data) - 1 - i)\n",
    "        return self.data[i:i+seq_len], self.data[i+1:i+1+seq_len].contiguous().view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs,bptt = 20,10\n",
    "train_dl = LanguageModelLoader(np.concatenate(train_ids), bs, bptt)\n",
    "valid_dl = LanguageModelLoader(np.concatenate(valid_ids), bs, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "self=train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.random.normal(self.bptt, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = max(5, int(np.random.normal(bptt, 5)))\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 20])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.data[i:i+seq_len].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 20])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.data[i+1:i+1+seq_len].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 20])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.data[i+1:i+1+seq_len].contiguous().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.data[i+1:i+1+seq_len].contiguous().view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10443"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use the AWD-LSTM from [Stephen Merity](https://arxiv.org/abs/1708.02182). First, we'll need all different kinds of dropouts. Dropout consists into replacing some coefficients by 0 with probability p. To ensure that the averga of the weights remains constant, we apply a correction to the weights that aren't nullified of a factor `1/(1-p)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dropout_mask(x:Tensor, sz:Collection[int], p:float):\n",
    "    \"Returns a dropout mask of the same type as x, size sz, with probability p to cancel an element.\"\n",
    "    return x.new(*sz).bernoulli_(1-p).div_(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 2., 2., 0., 0., 2., 2., 0., 2.],\n",
       "        [0., 0., 2., 2., 2., 2., 2., 0., 2., 2.],\n",
       "        [0., 0., 2., 0., 2., 0., 2., 0., 2., 2.],\n",
       "        [2., 0., 2., 0., 0., 2., 2., 2., 0., 2.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 2.],\n",
       "        [0., 0., 0., 2., 2., 0., 2., 2., 0., 0.],\n",
       "        [2., 2., 2., 0., 2., 2., 0., 0., 0., 2.],\n",
       "        [0., 2., 2., 0., 2., 0., 0., 0., 2., 0.],\n",
       "        [2., 2., 0., 2., 2., 2., 2., 2., 2., 0.],\n",
       "        [0., 0., 2., 0., 0., 0., 2., 2., 2., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10,10)\n",
    "dropout_mask(x, (10,10), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once with have a dropout mask `m`, applying the dropout to `x` is simply done by `x = x * m`. We create our own dropout mask and don't rely on pytorch dropout because we want to nullify the coefficients on the batch dimension but not the token dimension (aka the same coefficients are replaced by zero for each word in the sentence). \n",
    "\n",
    "Inside a RNN, a tensor x will have three dimensions: seq_len, bs, vocab_size, so we create a dropout mask for the last two dimensions and broadcast it to the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RNNDropout(nn.Module):\n",
    "    \"Dropout that is consistent on the seq_len dimension\"\n",
    "    \n",
    "    def __init__(self, p:float=0.5):\n",
    "        super().__init__()\n",
    "        self.p=p\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        if not self.training or self.p == 0.: return x\n",
    "        m = dropout_mask(x.data, (1, x.size(1), x.size(2)), self.p)\n",
    "        return x * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.7283,  0.7443, -1.8396, -2.7654,  0.3736,  0.6672,  1.2411,\n",
       "            0.8020, -0.2302, -1.0877],\n",
       "          [ 2.2003,  0.8253,  0.6388, -0.6059, -0.6410,  0.8697,  0.7311,\n",
       "            0.1968,  0.3669, -0.1167],\n",
       "          [-0.1711,  2.0904,  0.1090, -0.2663, -0.9678, -0.3236,  0.3334,\n",
       "            0.7960, -0.1871, -2.5345],\n",
       "          [-0.4101, -2.0172,  1.9497,  0.2155,  0.4823, -1.6743,  2.4850,\n",
       "           -0.5896, -0.5311, -0.2382],\n",
       "          [ 1.7063,  0.8261, -0.8135, -0.0204,  0.9086, -0.7822, -0.9808,\n",
       "           -1.6546, -0.0143, -0.7513]],\n",
       " \n",
       "         [[-0.6034,  1.2387,  0.7723,  0.2045, -0.5969,  1.0645, -0.0198,\n",
       "            0.3751,  0.1990, -1.9619],\n",
       "          [ 0.0461,  0.0713, -0.9382, -1.9040,  0.7329,  0.0634, -0.0106,\n",
       "            1.5115,  1.2739,  0.3524],\n",
       "          [-1.3722, -0.1292, -0.2983, -1.7732,  2.7751,  0.7476,  0.4863,\n",
       "           -0.8636, -0.4760,  0.8205],\n",
       "          [ 0.8279,  0.4220, -0.0188,  1.1219, -0.5122, -0.2561, -0.1091,\n",
       "           -1.1657, -1.6880, -0.5116],\n",
       "          [ 0.0134,  2.5264,  1.9402,  0.1886, -0.3089, -1.3456,  1.6305,\n",
       "           -1.1517, -0.0875, -0.6100]]]),\n",
       " tensor([[[-1.4566,  1.4886, -0.0000, -5.5308,  0.7472,  1.3345,  2.4821,\n",
       "            0.0000, -0.4605, -2.1754],\n",
       "          [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  1.7394,  1.4623,\n",
       "            0.0000,  0.0000, -0.2333],\n",
       "          [-0.0000,  4.1808,  0.0000, -0.5325, -1.9356, -0.6471,  0.0000,\n",
       "            0.0000, -0.3742, -0.0000],\n",
       "          [-0.8202, -4.0344,  3.8994,  0.0000,  0.9646, -0.0000,  4.9701,\n",
       "           -0.0000, -0.0000, -0.0000],\n",
       "          [ 3.4125,  1.6521, -0.0000, -0.0000,  1.8173, -0.0000, -0.0000,\n",
       "           -3.3092, -0.0000, -0.0000]],\n",
       " \n",
       "         [[-1.2069,  2.4773,  0.0000,  0.4091, -1.1938,  2.1289, -0.0396,\n",
       "            0.0000,  0.3979, -3.9239],\n",
       "          [ 0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.1267, -0.0212,\n",
       "            0.0000,  0.0000,  0.7048],\n",
       "          [-0.0000, -0.2584, -0.0000, -3.5464,  5.5502,  1.4951,  0.0000,\n",
       "           -0.0000, -0.9520,  0.0000],\n",
       "          [ 1.6558,  0.8440, -0.0376,  0.0000, -1.0243, -0.0000, -0.2183,\n",
       "           -0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0268,  5.0529,  0.0000,  0.0000, -0.6178, -0.0000,  0.0000,\n",
       "           -2.3034, -0.0000, -0.0000]]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_test = RNNDropout(0.5)\n",
    "x = torch.randn(2,5,10)\n",
    "x, dp_test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import warnings\n",
    "\n",
    "class WeightDropout(nn.Module):\n",
    "    \"A module that warps another layer in which some weights will be replaced by 0 during training.\"\n",
    "    \n",
    "    def __init__(self, module:Model, weight_p:float, layer_names:Collection[str]=['weight_hh_l0']):\n",
    "        super().__init__()\n",
    "        self.module,self.weight_p,self.layer_names = module,weight_p,layer_names\n",
    "        for layer in self.layer_names:\n",
    "            #Makes a copy of the weights of the selected layers.\n",
    "            w = getattr(self.module, layer)\n",
    "            self.register_parameter(f'{layer}_raw', nn.Parameter(w.data))\n",
    "    \n",
    "    def _setweights(self):\n",
    "        \"Applies dropout to the raw weights\"\n",
    "        for layer in self.layer_names:\n",
    "            raw_w = getattr(self, f'{layer}_raw')\n",
    "            self.module._parameters[layer] = F.dropout(raw_w, p=self.weight_p, training=self.training)\n",
    "            \n",
    "    def forward(self, *args:ArgStar):\n",
    "        self._setweights()\n",
    "        with warnings.catch_warnings():\n",
    "            #To avoid the warning that comes because the weights aren't flattened.\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            return self.module.forward(*args)\n",
    "    \n",
    "    def reset(self):\n",
    "        if hasattr(self.module, 'reset'): self.module.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeightDropout(\n",
       "  (module): LSTM(20, 20)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = nn.LSTM(20, 20)\n",
    "dp_module = WeightDropout(module, 0.5)\n",
    "opt = optim.SGD(dp_module.parameters(), 10)\n",
    "dp_module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,5,20)\n",
    "x.requires_grad_(requires_grad=True)\n",
    "h = (torch.zeros(1,5,20), torch.zeros(1,5,20))\n",
    "for _ in range(5): x,h = dp_module(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1631, -0.1101,  0.2537,  ..., -0.0874, -0.0000,  0.0000],\n",
       "         [ 0.0985,  0.4257,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0669,  ..., -0.2192, -0.2993, -0.0000],\n",
       "         ...,\n",
       "         [ 0.0644, -0.0000,  0.0000,  ..., -0.4386, -0.0000,  0.0000],\n",
       "         [ 0.3466, -0.3525,  0.0000,  ...,  0.0000,  0.3990,  0.0000],\n",
       "         [-0.4137, -0.0000,  0.0995,  ..., -0.4364, -0.1720,  0.1987]],\n",
       "        grad_fn=<MulBackward0>), Parameter containing:\n",
       " tensor([[-0.0816, -0.0550,  0.1269,  ..., -0.0437, -0.2212,  0.0648],\n",
       "         [ 0.0492,  0.2128,  0.2189,  ...,  0.1867, -0.1781,  0.1222],\n",
       "         [ 0.2103,  0.0843, -0.0335,  ..., -0.1096, -0.1496, -0.0910],\n",
       "         ...,\n",
       "         [ 0.0322, -0.1078,  0.0856,  ..., -0.2193, -0.1736,  0.0777],\n",
       "         [ 0.1733, -0.1762,  0.1076,  ...,  0.0995,  0.1995,  0.1258],\n",
       "         [-0.2069, -0.1522,  0.0498,  ..., -0.2182, -0.0860,  0.0993]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randint(0,20,(10,)).long()\n",
    "loss = F.nll_loss(x.view(-1,20), target)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([[-0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0001, -0.0000],\n",
       "         [ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [-0.0000,  0.0000, -0.0008,  ..., -0.0006,  0.0004, -0.0006],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0001,  0.0000,  ..., -0.0006, -0.0001,  0.0000],\n",
       "         [ 0.0001, -0.0000,  0.0002,  ...,  0.0002, -0.0001,  0.0005],\n",
       "         [-0.0000,  0.0001, -0.0001,  ..., -0.0000,  0.0001, -0.0002]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, w_raw = getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')\n",
    "w.grad, w_raw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1631, -0.1101,  0.2537,  ..., -0.0874, -0.0000,  0.0000],\n",
       "         [ 0.0985,  0.4257,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.0669,  ..., -0.2192, -0.2993, -0.0000],\n",
       "         ...,\n",
       "         [ 0.0644, -0.0000,  0.0000,  ..., -0.4386, -0.0000,  0.0000],\n",
       "         [ 0.3466, -0.3525,  0.0000,  ...,  0.0000,  0.3990,  0.0000],\n",
       "         [-0.4137, -0.0000,  0.0995,  ..., -0.4364, -0.1720,  0.1987]],\n",
       "        grad_fn=<MulBackward0>), Parameter containing:\n",
       " tensor([[-0.0816, -0.0550,  0.1268,  ..., -0.0437, -0.2225,  0.0652],\n",
       "         [ 0.0491,  0.2131,  0.2190,  ...,  0.1868, -0.1779,  0.1223],\n",
       "         [ 0.2103,  0.0843, -0.0257,  ..., -0.1038, -0.1532, -0.0851],\n",
       "         ...,\n",
       "         [ 0.0321, -0.1066,  0.0855,  ..., -0.2137, -0.1728,  0.0777],\n",
       "         [ 0.1727, -0.1762,  0.1053,  ...,  0.0977,  0.2009,  0.1212],\n",
       "         [-0.2066, -0.1533,  0.0509,  ..., -0.2178, -0.0865,  0.1014]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(dp_module.module, 'weight_hh_l0'),getattr(dp_module,'weight_hh_l0_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EmbeddingDropout(nn.Module):\n",
    "    \"Applies dropout in the embedding layer by zeroing out some elements of the embedding vector.\"\n",
    "    \n",
    "    def __init__(self, emb:Model, embed_p:float):\n",
    "        super().__init__()\n",
    "        self.emb,self.embed_p = emb,embed_p\n",
    "        self.pad_idx = self.emb.padding_idx\n",
    "        if self.pad_idx is None: self.pad_idx = -1\n",
    "\n",
    "    def forward(self, words:LongTensor, scale:Optional[float]=None) -> Tensor:\n",
    "        if self.training and self.embed_p != 0:\n",
    "            size = (self.emb.weight.size(0),1)\n",
    "            mask = dropout_mask(self.emb.weight.data, size, self.embed_p)\n",
    "            masked_embed = self.emb.weight * mask\n",
    "        else: masked_embed = self.emb.weight\n",
    "        if scale: masked_embed.mul_(scale)\n",
    "        return F.embedding(words, masked_embed, self.pad_idx, self.emb.max_norm,\n",
    "                           self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = nn.Embedding(100,20, padding_idx=0)\n",
    "enc_dp = EmbeddingDropout(enc, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0,100,(25,)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7143,  0.0896,  1.5000,  2.1003,  0.0004, -3.6886,  2.0353, -2.4099,\n",
       "         -0.9990,  1.4987,  1.3285, -2.3275, -0.9443,  1.8773,  0.7688, -1.6824,\n",
       "          0.7480, -1.6076, -1.6210, -1.4068],\n",
       "        [-0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-1.2547, -2.4881,  2.8908,  2.0062, -3.5332, -0.2465, -1.5952,  2.0468,\n",
       "         -0.8801, -1.0021,  1.0353,  0.5487,  1.7424, -1.7696, -2.3166,  0.4942,\n",
       "         -0.5003, -3.9225,  3.0615, -0.2013],\n",
       "        [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0000],\n",
       "        [ 0.4062, -1.2235,  0.7846, -1.8064,  1.4518, -0.6982, -0.1204,  0.5332,\n",
       "         -1.4451, -0.1833,  3.7011,  0.0184,  2.6993, -0.3884,  2.3557,  1.1446,\n",
       "         -1.4068,  0.2000,  1.3975,  0.4535],\n",
       "        [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-2.4473, -0.9877, -0.3063,  2.5940,  0.7296, -5.6734, -1.4352,  2.9366,\n",
       "         -3.0336, -1.2371,  0.1166, -1.8974, -0.1804,  5.8191, -6.4693, -3.1460,\n",
       "         -1.0154,  0.0989, -0.7092,  3.6979],\n",
       "        [-0.2206, -1.5403, -1.2554,  1.6216,  0.8532, -2.5243,  4.9705,  0.3192,\n",
       "         -0.4822,  1.7657,  0.1430,  2.9319, -2.4030, -2.7249,  2.3449, -0.3918,\n",
       "         -3.8734, -1.5998, -1.8973, -1.6580],\n",
       "        [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
       "         -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
       "          0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [ 0.5739, -3.1854,  1.0630, -2.6615,  0.3136,  1.6297,  0.1552, -0.5121,\n",
       "          2.3843, -2.7195, -0.8649, -5.0739, -0.1174, -0.7436, -0.6678, -1.0228,\n",
       "          1.3353,  0.5905, -1.5024,  3.9652],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000],\n",
       "        [ 1.4127, -1.0488, -0.4981, -0.3003,  2.3310, -0.0942, -1.2596, -2.5400,\n",
       "          1.1845,  2.0485,  0.8448,  1.3262,  1.5194, -1.3146,  1.8392, -3.8241,\n",
       "         -0.6158, -0.3492, -0.9309, -2.8997],\n",
       "        [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "         -0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
       "         -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "          0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
       "         -0.0000,  0.0000,  0.0000, -0.0000],\n",
       "        [ 0.2883, -0.2053, -0.7464,  1.5435, -0.1825, -0.3947,  0.4201, -4.5498,\n",
       "         -0.0014,  1.5503,  1.9056, -1.2087, -2.5845,  0.5961,  1.4286, -3.8571,\n",
       "          0.7784,  0.0274, -2.7719, -4.6577],\n",
       "        [-4.7703, -1.0850,  0.5983,  0.3188, -0.0222,  3.7964,  2.1740,  0.9633,\n",
       "          1.5262, -0.9994,  0.7808, -0.9616, -1.6563, -3.0915,  3.9450,  0.0594,\n",
       "          3.3155, -0.5923, -0.0290,  0.3789],\n",
       "        [ 3.2526,  2.0393,  2.6633,  1.1224,  1.3141, -1.3508,  1.3869,  2.1207,\n",
       "          1.7434,  1.1371,  0.2505, -4.0842,  2.5290,  0.6258, -0.3191,  1.0306,\n",
       "          3.5767, -1.2454, -2.1106,  2.3005],\n",
       "        [-0.7744,  3.3703, -4.7791,  0.8099, -4.0428, -4.3502,  1.1605,  0.3534,\n",
       "          0.4043, -2.9390, -1.6585, -3.6828,  1.3342, -2.0103, -4.9145, -2.5152,\n",
       "         -1.9733, -0.5137, -1.7915, -2.5981],\n",
       "        [ 0.2992,  1.7298, -1.6442, -0.9758,  0.0626, -3.6860, -2.7164, -1.4297,\n",
       "         -3.3261,  1.2460, -1.9711,  0.4364,  3.7856,  0.7935,  1.0363,  1.4415,\n",
       "          1.5936, -0.5944, -0.0448, -0.4421],\n",
       "        [-4.7703, -1.0850,  0.5983,  0.3188, -0.0222,  3.7964,  2.1740,  0.9633,\n",
       "          1.5262, -0.9994,  0.7808, -0.9616, -1.6563, -3.0915,  3.9450,  0.0594,\n",
       "          3.3155, -0.5923, -0.0290,  0.3789],\n",
       "        [ 0.5400, -1.2976, -0.9406, -2.1925,  1.6763, -2.5468,  0.7608,  1.4094,\n",
       "         -0.4537,  0.7105,  2.9785, -1.8909, -0.7010,  0.3521,  0.9883, -1.4023,\n",
       "         -2.5707,  0.0099,  0.4931,  5.6270]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. AWD-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def repackage_var(h:Tensors) -> Tensors:\n",
    "    \"Detaches h from its history.\"\n",
    "    return h.detach() if type(h) == torch.Tensor else tuple(repackage_var(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RNNCore(nn.Module):\n",
    "    \"AWD-LSTM/QRNN inspired by https://arxiv.org/abs/1708.02182\"\n",
    "\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, vocab_sz:int, emb_sz:int, n_hid:int, n_layers:int, pad_token:int, bidir:bool=False,\n",
    "                 hidden_p:float=0.2, input_p:float=0.6, embed_p:float=0.1, weight_p:float=0.5, qrnn:bool=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.bs,self.qrnn,self.ndir = 1, qrnn,(2 if bidir else 1)\n",
    "        self.emb_sz,self.n_hid,self.n_layers = emb_sz,n_hid,n_layers\n",
    "        self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
    "        self.encoder_dp = EmbeddingDropout(self.encoder, embed_p)\n",
    "        if self.qrnn:\n",
    "            #Using QRNN requires cupy: https://github.com/cupy/cupy\n",
    "            from qrnn import QRNNLayer\n",
    "            self.rnns = [QRNNLayer(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.ndir,\n",
    "                                   save_prev_x=True, zoneout=0, window=2 if l == 0 else 1, output_gate=True, \n",
    "                                   use_cuda=torch.cuda.is_available()) for l in range(n_layers)]\n",
    "            if weight_p != 0.:\n",
    "                for rnn in self.rnns:\n",
    "                    rnn.linear = WeightDropout(rnn.linear, weight_p, layer_names=['weight'])\n",
    "        else:\n",
    "            self.rnns = [nn.LSTM(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.ndir,\n",
    "                1, bidirectional=bidir) for l in range(n_layers)]\n",
    "            if weight_p != 0.: self.rnns = [WeightDropout(rnn, weight_p) for rnn in self.rnns]\n",
    "        self.rnns = torch.nn.ModuleList(self.rnns)\n",
    "        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])\n",
    "\n",
    "    def forward(self, input:LongTensor) -> Tuple[Tensor,Tensor]:\n",
    "        sl,bs = input.size()\n",
    "        if bs!=self.bs:\n",
    "            self.bs=bs\n",
    "            self.reset()\n",
    "        raw_output = self.input_dp(self.encoder_dp(input))\n",
    "        new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            raw_output, new_h = rnn(raw_output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n",
    "            outputs.append(raw_output)\n",
    "        self.hidden = repackage_var(new_hidden)\n",
    "        return raw_outputs, outputs\n",
    "\n",
    "    def one_hidden(self, l:int) -> Tensor:\n",
    "        \"Returns one hidden state\"\n",
    "        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz)//self.ndir\n",
    "        return self.weights.new(self.ndir, self.bs, nh).zero_()\n",
    "\n",
    "    def reset(self):\n",
    "        \"Resets the hidden states\"\n",
    "        [r.reset() for r in self.rnns if hasattr(r, 'reset')]\n",
    "        self.weights = next(self.parameters()).data\n",
    "        if self.qrnn: self.hidden = [self.one_hidden(l) for l in range(self.n_layers)]\n",
    "        else: self.hidden = [(self.one_hidden(l), self.one_hidden(l)) for l in range(self.n_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LinearDecoder(nn.Module):\n",
    "    \"To go on top of a RNN_Core module\"\n",
    "    \n",
    "    initrange=0.1\n",
    "    \n",
    "    def __init__(self, n_out:int, n_hid:int, output_p:float, tie_encoder:Model=None, bias:bool=True):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n",
    "        self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.output_dp = RNNDropout(output_p)\n",
    "        if bias: self.decoder.bias.data.zero_()\n",
    "        if tie_encoder: self.decoder.weight = tie_encoder.weight\n",
    "\n",
    "    def forward(self, input:Tuple[Tensor,Tensor]) -> Tuple[Tensor,Tensor,Tensor]:\n",
    "        raw_outputs, outputs = input\n",
    "        output = self.output_dp(outputs[-1])\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded, raw_outputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SequentialRNN(nn.Sequential):\n",
    "    \"A sequential module that passes the reset call to its children.\"\n",
    "    def reset(self):\n",
    "        for c in self.children():\n",
    "            if hasattr(c, 'reset'): c.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_language_model(vocab_sz:int, emb_sz:int, n_hid:int, n_layers:int, pad_token:int, tie_weights:bool=True, \n",
    "                       qrnn:bool=False, bias:bool=True, output_p:float=0.4, hidden_p:float=0.2, input_p:float=0.6, \n",
    "                       embed_p:float=0.1, weight_p:float=0.5) -> Model:\n",
    "    \"To create a full AWD-LSTM\"\n",
    "    rnn_enc = RNNCore(vocab_sz, emb_sz, n_hid=n_hid, n_layers=n_layers, pad_token=pad_token, qrnn=qrnn,\n",
    "                 hidden_p=hidden_p, input_p=input_p, embed_p=embed_p, weight_p=weight_p)\n",
    "    enc = rnn_enc.encoder if tie_weights else None\n",
    "    return SequentialRNN(rnn_enc, LinearDecoder(vocab_sz, emb_sz, output_p, tie_encoder=enc, bias=bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_model = get_language_model(500, 20, 100, 2, 0, qrnn=True)\n",
    "tst_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0, 500, (10,5)).long()\n",
    "z = tst_model(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Callback to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class GradientClipping(Callback):\n",
    "    \"To do gradient clipping during training.\"\n",
    "    learn:Learner\n",
    "    clip:float\n",
    "\n",
    "    def on_backward_end(self, **kwargs):\n",
    "        if self.clip:  nn.utils.clip_grad_norm_(self.learn.model.parameters(), self.clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class RNNTrainer(Callback):\n",
    "    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR\"\n",
    "    learn:Learner\n",
    "    bptt:int\n",
    "    alpha:float=0.\n",
    "    beta:float=0.\n",
    "    adjust:bool=True\n",
    "    \n",
    "    def on_loss_begin(self, last_output:Tuple[Tensor,Tensor,Tensor], **kwargs):\n",
    "        #Save the extra outputs for later and only returns the true output.\n",
    "        self.raw_out,self.out = last_output[1],last_output[2]\n",
    "        return last_output[0]\n",
    "    \n",
    "    def on_backward_begin(self, last_loss:Rank0Tensor, last_input:Tensor, last_output:Tensor, **kwargs):\n",
    "        #Adjusts the lr to the bptt selected\n",
    "        if self.adjust: self.learn.opt.lr *= last_input.size(0) / self.bptt\n",
    "        #AR and TAR\n",
    "        if self.alpha != 0.:  last_loss += (self.alpha * self.out[-1].pow(2).mean()).sum()\n",
    "        if self.beta != 0.:\n",
    "            h = self.raw_out[-1]\n",
    "            if len(h)>1: last_loss += (self.beta * (h[1:] - h[:-1]).pow(2).mean()).sum()\n",
    "        return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sz, nh, nl = 400, 1150, 3\n",
    "model = get_language_model(vocab_size, emb_sz, nh, nl, 0, input_p=0.6, output_p=0.4, weight_p=0.5, \n",
    "                           embed_p=0.1, hidden_p=0.2)\n",
    "learn = Learner(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.opt_fn = partial(optim.Adam, betas=(0.8,0.99))\n",
    "learn.callbacks.append(RNNTrainer(learn, bptt, alpha=2, beta=1))\n",
    "learn.callback_fns = [partial(GradientClipping, clip=0.12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_one_cycle(learn, 1, 5e-3, (0.8,0.7), wd=1.2e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastaiv1]",
   "language": "python",
   "name": "conda-env-fastaiv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
